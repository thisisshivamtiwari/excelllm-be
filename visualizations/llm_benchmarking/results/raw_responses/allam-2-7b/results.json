[
  {
    "question_id": "Complex_13",
    "question_text": "How does the average rework count for 'Widget-A' differ between Line-1 and Line-2?",
    "category": "Complex",
    "model_id": "allam-2-7b",
    "methodology_response": "To answer the question about the average rework count for 'Widget-A' differing between Line-1 and Line-2, we will follow these steps:\n\n1. Connect to the database and select the required tables:\n   - Production_logs (to get the Actual_Qty and Downtime_Minutes)\n   - Quality_control (to get the Rework_Count)\n   - Maintenance_logs (to get the Downtime_Hours)\n   - Inventory_logs (to get the Consumption_Kg and Closing_Stock_Kg)\n\n2. Filter the data based on the product 'Widget-A':\n   - Production_logs: Filter by Product = 'Widget-A'\n   - Quality_control: Filter by Product = 'Widget-A'\n   - Maintenance_logs: Filter by Machine = 'Widget-A'\n   - Inventory_logs: Filter by Material_Code = 'Widget-A'\n\n3. Calculate the total production hours for each line:\n   - Production_logs: Calculate the sum of Downtime_Minutes and multiply by 60 to get total production hours\n\n4. Calculate the total rework hours for each line:\n   - Quality_control: Calculate the sum of Rework_Count and multiply by 60 to get total rework hours\n\n5. Calculate the total maintenance hours for each line:\n   - Maintenance_logs: Calculate the sum of Downtime_Hours\n\n6. Calculate the total consumption for each line:\n   - Inventory_logs: Calculate the sum of Consumption_Kg and multiply by 1000 to get total consumption in kg\n\n7. Calculate the total wastage for each line:\n   - Inventory_logs: Calculate the sum of Wastage_Kg\n\n8. Calculate the total production hours per hour for each line:\n   - Production_logs: Calculate the total production hours divided by the total production hours for each line\n\n9. Calculate the total rework hours per hour for each line:\n   - Quality_control: Calculate the total rework hours divided by the total production hours for each line\n\n10. Calculate the total maintenance hours per hour for each line:\n    - Maintenance_logs: Calculate the total maintenance hours divided by the total production hours for each line\n\n11. Calculate the total consumption per hour for each line:\n    - Inventory_logs: Calculate the total consumption divided by the total production hours for each line\n\n12. Calculate the total wastage per hour for each line:\n    - Inventory_logs: Calculate the total wastage divided by the total production hours for each line\n\n13. Calculate the total production hours per hour for each line:\n    - Production_logs: Calculate the total production hours divided by the total production hours for each line\n\n14. Calculate the total rework hours per hour for each line:\n    - Quality_control: Calculate the total rework hours divided by the total production hours for each line\n\n15. Calculate the total maintenance hours per hour for each line:\n    - Maintenance_logs: Calculate the total maintenance hours divided by the total production hours for each line\n\n16. Calculate the total consumption per hour for each line:\n    - Inventory_logs: Calculate the total consumption divided by the total production hours for each line\n\n17. Calculate the total wastage per hour for each line:\n    - Inventory_logs: Calculate the total wastage divided by the total production hours for each line\n\n18. Calculate the total production hours per hour for each line:\n    - Production_logs: Calculate the total production hours divided by the total production hours for each line\n\n19. Calculate the total rework hours per hour for each line:\n    - Quality_control: Calculate the total rework hours divided by the total production hours for each line\n\n20. Calculate the total maintenance hours per hour for each line:\n    - Maintenance_logs: Calculate the total maintenance hours divided by the total production hours for each line\n\n21. Calculate the total consumption per hour for each line:\n    - Inventory_logs: Calculate the total consumption divided by the total production hours for each line\n\n22. Calculate the total wastage per hour for each line:\n    - Inventory_",
    "sql_response": "To find the average rework count for 'Widget-A' on Line-1 and Line-2, we can use the following SQL query:\n\n```sql\nSELECT Line, AVG(Rework_Count) AS Avg_Rework_Count\nFROM (\n  SELECT Line, Machine, Maintenance_Type, Breakdown_Date, Downtime_Hours, Rework_Count, SUM(CASE WHEN Machine = 'Machine-M1' THEN Consumption_Kg ELSE 0 END) AS Widget_A_Consumption_Line1,\n  SUM(CASE WHEN Machine = 'Machine-M2' THEN Consumption_Kg ELSE 0 END) AS Widget_A_Consumption_Line2,\n  SUM(CASE WHEN Machine = 'Machine-M1' THEN Consumption_Kg ELSE 0 END) AS Widget_A_Consumption_Line1,\n  SUM(CASE WHEN Machine = 'Machine-M2' THEN Consumption_Kg ELSE 0 END) AS Widget_A_Consumption_Line2,\n  SUM(CASE WHEN Machine = 'Machine-M1' THEN Consumption_Kg ELSE 0 END) AS Widget_A_Consumption_Line1,\n  SUM(CASE WHEN Machine = 'Machine-M2' THEN Consumption_Kg ELSE 0 END) AS Widget_A_Consumption_Line2,\n  SUM(CASE WHEN Machine = 'Machine-M1' THEN Consumption_Kg ELSE 0 END) AS Widget_A_Consumption_Line1,\n  SUM(CASE WHEN Machine = 'Machine-M2' THEN Consumption_Kg ELSE 0 END) AS Widget_A_Consumption_Line2,\n  SUM(CASE WHEN Machine = 'Machine-M1' THEN Consumption_Kg ELSE 0 END) AS Widget_A_Consumption_Line1,\n  SUM(CASE WHEN Machine = 'Machine-M2' THEN Consumption_Kg ELSE 0 END) AS Widget_A_Consumption_Line2,\n  SUM(CASE WHEN Machine = 'Machine-M1' THEN Consumption_Kg ELSE 0 END) AS Widget_A_Consumption_Line1,\n  SUM(CASE WHEN Machine = 'Machine-M2' THEN Consumption_Kg ELSE 0 END) AS Widget_A_Consumption_Line2\nFROM production_logs\nGROUP BY Line\n```\n\nThis query joins the `production_logs` table with the `inventory_logs` table on the `Machine` column to get the consumption data for each line. Then, it calculates the consumption for each line using conditional aggregation. Finally, it groups the result by line and calculates the average consumption for each line. \n\nPlease note that you will need to replace `production_logs` and `inventory_logs` with the actual table names in your database. ",
    "table_selection_response": "{\n  \"tables\": [\n    \"production_logs\",\n    \"quality_control\",\n    \"inventory_logs\"\n  ],\n  \"columns\": [\n    \"Product\",\n    \"Rework_Count\",\n    \"Line\"\n  ]\n} ",
    "methodology_score": 55.55555555555556,
    "sql_score": 32.388888888888886,
    "table_column_score": 80.0,
    "response_quality_score": 98.1671040058136,
    "overall_score": 57.81948817835914,
    "methodology_details": {
      "method": "keyword_fallback",
      "overlap_count": 10,
      "expected_keyword_count": 18,
      "response_keyword_count": 76
    },
    "sql_details": {
      "table_match": 0.0,
      "column_match": 22.22222222222222,
      "aggregate_match": 66.66666666666666,
      "clause_match": 75.0,
      "fuzzy_score": 15.000000000000002,
      "overall_score": 32.388888888888886,
      "expected_tables": [
        "quality_control"
      ],
      "generated_tables": [
        "production_logs"
      ],
      "expected_columns": [
        "line",
        "product",
        "rework_count"
      ],
      "generated_columns": [
        "case when machine = machine-m2 then consumption_kg else 0 end",
        "case when machine = machine-m1 then consumption_kg else 0 end",
        "breakdown_date",
        "maintenance_type",
        "machine",
        "line",
        "downtime_hours",
        "rework_count"
      ],
      "has_valid_sql": true
    },
    "table_column_details": {
      "overall_score": 80.0,
      "table_score": 50.0,
      "column_score": 100.0,
      "table_precision": 33.33333333333333,
      "table_recall": 100.0,
      "column_precision": 100.0,
      "column_recall": 100.0,
      "tables_correct": [
        "quality_control"
      ],
      "tables_missing": [],
      "tables_extra": [
        "production_logs",
        "inventory_logs"
      ],
      "columns_correct": [
        "product",
        "line",
        "rework_count"
      ],
      "columns_missing": [],
      "columns_extra": [],
      "expected_tables": [
        "quality_control"
      ],
      "generated_tables": [
        "production_logs",
        "quality_control",
        "inventory_logs"
      ],
      "expected_columns": [
        "product",
        "line",
        "rework_count"
      ],
      "generated_columns": [
        "product",
        "line",
        "rework_count"
      ]
    },
    "total_latency_ms": 1832.8959941864014,
    "total_tokens": 3320,
    "errors": [],
    "timestamp": "2025-11-30T13:06:40.671592"
  },
  {
    "question_id": "Easy_15",
    "question_text": "Which inspector had the highest number of reworked items?",
    "category": "Easy",
    "model_id": "allam-2-7b",
    "methodology_response": "To answer the question about which inspector had the highest number of reworked items, we will follow these steps:\n\n1. Connect to the database and select the necessary tables:\n   - Production Logs table (production_logs) to get the inspection data\n   - Quality Control table (quality_control) to get the rework data\n\n2. Filter the Production Logs table to get the inspection data for the specific product and date range:\n   - Filter by Product and Date (from the production_logs table)\n\n3. Filter the Quality Control table to get the rework data for the specific inspection date:\n   - Filter by Inspection_Date (from the quality_control table)\n\n4. Join the filtered Production Logs and Quality Control tables on the Inspection_Date:\n   - Join the tables on the Inspection_Date column\n\n5. Calculate the total rework count for each inspector:\n   - Group by Inspector_Name and sum the Rework_Count column from the joined Quality Control table\n\n6. Sort the result by the highest rework count:\n   - Sort the result in descending order based on the sum of Rework_Count\n\n7. Select the top record(s) to get the inspector(s) with the highest rework count:\n   - Select the first record(s) from the sorted result\n\n8. Display the inspector(s) with the highest rework count:\n   - Display the Inspector_Name column from the selected records\n\nPlease note that the specific SQL queries will depend on the database management system being used. The above steps outline the general approach to solve the problem. ",
    "sql_response": "To find the inspector with the highest number of reworked items, we can join the `quality_control` and `inventory_logs` tables based on the `Machine` column, which is common to both tables. Then, we can group the results by `Inspector_Name` and `Machine`, and count the number of `Rework_Count` for each inspector. Finally, we can order the results by the count in descending order to find the inspector with the highest count.\n\nHere is the SQL query:\n\n```sql\nSELECT qc.Inspector_Name, COUNT(il.Machine) AS Rework_Count\nFROM quality_control qc\nINNER JOIN inventory_logs il ON qc.Machine = il.Machine\nGROUP BY qc.Inspector_Name, qc.Machine\nORDER BY Rework_Count DESC;\n```\n\nThis query will return the inspector with the highest number of reworked items along with the count of machines they inspected. ",
    "table_selection_response": "{\n  \"tables\": [\n    \"quality_control\"\n  ],\n  \"columns\": [\n    \"Inspector_Name\",\n    \"Rework_Count\"\n  ]\n} ",
    "methodology_score": 100,
    "sql_score": 49.72527472527472,
    "table_column_score": 100.0,
    "response_quality_score": 98.86612296104431,
    "overall_score": 82.29045844995059,
    "methodology_details": {
      "method": "keyword_fallback",
      "overlap_count": 11,
      "expected_keyword_count": 11,
      "response_keyword_count": 84
    },
    "sql_details": {
      "table_match": 50.0,
      "column_match": 40.0,
      "aggregate_match": 50.0,
      "clause_match": 57.14285714285714,
      "fuzzy_score": 57.692307692307686,
      "overall_score": 49.72527472527472,
      "expected_tables": [
        "quality_control"
      ],
      "generated_tables": [
        "inventory_logs",
        "quality_control"
      ],
      "expected_columns": [
        "sum",
        "rework_count",
        "inspector_name"
      ],
      "generated_columns": [
        "qc",
        "rework_count",
        "inspector_name",
        "machine"
      ],
      "has_valid_sql": true
    },
    "table_column_details": {
      "overall_score": 100.0,
      "table_score": 100.0,
      "column_score": 100.0,
      "table_precision": 100.0,
      "table_recall": 100.0,
      "column_precision": 100.0,
      "column_recall": 100.0,
      "tables_correct": [
        "quality_control"
      ],
      "tables_missing": [],
      "tables_extra": [],
      "columns_correct": [
        "rework_count",
        "inspector_name"
      ],
      "columns_missing": [],
      "columns_extra": [],
      "expected_tables": [
        "quality_control"
      ],
      "generated_tables": [
        "quality_control"
      ],
      "expected_columns": [
        "rework_count",
        "inspector_name"
      ],
      "generated_columns": [
        "rework_count",
        "inspector_name"
      ]
    },
    "total_latency_ms": 1133.8770389556885,
    "total_tokens": 2106,
    "errors": [],
    "timestamp": "2025-11-30T13:06:48.065503"
  },
  {
    "question_id": "Easy_4",
    "question_text": "What is the total number of components reworked in Line-2?",
    "category": "Easy",
    "model_id": "allam-2-7b",
    "methodology_response": "To find the total number of components reworked in Line-2, we will follow these steps:\n\n1. Connect to the database and select the necessary tables:\n   - Production Logs (production_logs) table to get the production data\n   - Quality Control (quality_control) table to get the rework data\n\n2. Filter the Production Logs table for Line-2:\n   - Join the production_logs table with itself on the Shift, Line_Machine, and Product columns to get the data for both shifts (Shift1 and Shift2) and both machines (Machine1 and Machine2) on the same day.\n   - Filter the joined table for Line_Machine = 'Line-2' and Shift = 'Shift2' to get the data for Line-2 on Shift2 only.\n\n3. Filter the Quality Control table for Line-2:\n   - Join the quality_control table with the filtered production_logs table on the Product column to match the production data with the rework data.\n   - Filter the joined table for Line_Machine = 'Line-2' to get the rework data for Line-2 only.\n\n4. Calculate the rework quantity:\n   - Join the filtered quality_control table with itself on the Product column to get the rework data for both shifts (Shift1 and Shift2) and both machines (Machine1 and Machine2) on the same day.\n   - Filter the joined table for Shift = 'Shift2' to get the rework data for Line-2 on Shift2 only.\n   - Calculate the SUM of the Rework_Qty column to get the total rework quantity for Line-2 on Shift2.\n\n5. Calculate the total production quantity:\n   - Join the filtered production_logs table with itself on the Product column to get the production data for both shifts (Shift1 and Shift2) and both machines (Machine1 and Machine2) on the same day.\n   - Filter the joined table for Shift = 'Shift2' to get the production data for Line-2 on Shift2 only.\n   - Calculate the SUM of the Actual_Qty column to get the total production quantity for Line-2 on Shift2.\n\n6. Calculate the rework rate:\n   - Calculate the ratio of the rework quantity (from step 4) to the production quantity (from step 5).\n\n7. Calculate the total reworked components:\n   - Multiply the rework rate (from step 6) by the total production quantity (from step 5).\n\n8. Calculate the rework rate per hour:\n   - Calculate the total rework time (from step 6) divided by the total production time (from step 5).\n\n9. Calculate the rework rate per hour per component:\n   - Multiply the rework rate per hour (from step 8) by the reworked components (from step 7).\n\n10. Calculate the rework rate per hour per component per hour:\n    - Multiply the rework rate per hour per component (from step 9) by the number of hours worked on Shift2 (from step 5).\n\n11. Calculate the rework rate per hour per component per hour per hour:\n    - Multiply the rework rate per hour per component per hour (from step 10) by the number of hours worked on Shift2 (from step 5).\n\n12. Calculate the rework rate per hour per component per hour per hour per hour:\n    - Multiply the rework rate per hour per component per hour per hour (from step 11) by the number of hours worked on Shift2 (from step 5).\n\n13. Calculate the rework rate per hour per component per hour per hour per hour per hour:\n    - Multiply the rework rate per hour per component per hour per hour per hour (from step 12) by the number of hours worked on Shift2 (from step 5).\n\n14. Calculate the rework rate per hour per component per hour per hour per hour per hour:\n    - Multiply the rework rate per hour per component per hour per hour per hour (from step 13) by the number of hours worked on Shift2 (from step 5).\n\n15. Calculate the rework rate per hour per component per hour per hour per hour",
    "sql_response": "To find the total number of components reworked in Line-2, we can use a combination of JOINs and aggregation functions in SQL. Here's the query:\n\n```sql\nSELECT SUM(maintenance_logs.Rework_Count) AS Total_Rework_Count\nFROM maintenance_logs\nJOIN inventory_logs ON maintenance_logs.Machine = inventory_logs.Material_Code\nWHERE inventory_logs.Material_Code = 'Plastic-PVC' AND maintenance_logs.Line = 'Line-2';\n```\n\nThis query joins the `maintenance_logs` and `inventory_logs` tables on the `Machine` and `Material_Code` columns respectively. We then filter the results for `Material_Code` equal to 'Plastic-PVC' and `Line` equal to 'Line-2'. Finally, we calculate the sum of the `Rework_Count` column from the `maintenance_logs` table using the `SUM()` function and alias it as `Total_Rework_Count`. ",
    "table_selection_response": "{\n  \"tables\": [\n    \"quality_control\"\n  ],\n  \"columns\": [\n    \"Rework_Count\"\n  ]\n} ",
    "methodology_score": 71.42857142857143,
    "sql_score": 42.81581740976645,
    "table_column_score": 80.0,
    "response_quality_score": 95.47374725341797,
    "overall_score": 65.96148224733149,
    "methodology_details": {
      "method": "keyword_fallback",
      "overlap_count": 5,
      "expected_keyword_count": 7,
      "response_keyword_count": 90
    },
    "sql_details": {
      "table_match": 0.0,
      "column_match": 50.0,
      "aggregate_match": 66.66666666666666,
      "clause_match": 75.0,
      "fuzzy_score": 38.21656050955414,
      "overall_score": 42.81581740976645,
      "expected_tables": [
        "quality_control"
      ],
      "generated_tables": [
        "maintenance_logs",
        "inventory_logs"
      ],
      "expected_columns": [
        "line",
        "rework_count"
      ],
      "generated_columns": [
        "rework_count"
      ],
      "has_valid_sql": true
    },
    "table_column_details": {
      "overall_score": 80.0,
      "table_score": 100.0,
      "column_score": 66.66666666666666,
      "table_precision": 100.0,
      "table_recall": 100.0,
      "column_precision": 100.0,
      "column_recall": 50.0,
      "tables_correct": [
        "quality_control"
      ],
      "tables_missing": [],
      "tables_extra": [],
      "columns_correct": [
        "rework_count"
      ],
      "columns_missing": [
        "line"
      ],
      "columns_extra": [],
      "expected_tables": [
        "quality_control"
      ],
      "generated_tables": [
        "quality_control"
      ],
      "expected_columns": [
        "line",
        "rework_count"
      ],
      "generated_columns": [
        "rework_count"
      ]
    },
    "total_latency_ms": 4526.252746582031,
    "total_tokens": 2766,
    "errors": [],
    "timestamp": "2025-11-30T13:06:59.197423"
  },
  {
    "question_id": "Complex_26",
    "question_text": "What is the impact of preventive maintenance on the subsequent breakdown frequency for Machine-M1?",
    "category": "Complex",
    "model_id": "allam-2-7b",
    "methodology_response": "To answer the question about the impact of preventive maintenance on the subsequent breakdown frequency for Machine-M1, we will follow these steps:\n\n1. Connect to the database and select the necessary tables:\n   - Production Logs (production_logs) table to get the breakdown dates and machine information\n   - Maintenance Logs (maintenance_logs) table to get the maintenance dates and machine information\n   - Quality Control (quality_control) table to get the inspection dates and machine information\n\n2. Filter the data based on Machine-M1:\n   - Filter the Production Logs table for Machine-M1\n   - Filter the Maintenance Logs table for Machine-M1\n   - Filter the Quality Control table for Machine-M1\n\n3. Calculate the breakdown frequency:\n   - Calculate the number of breakdowns by counting the number of times Machine-M1 experienced a breakdown.\n\n4. Filter the data for preventive maintenance:\n   - Filter the Maintenance Logs table for preventive maintenance events on Machine-M1\n\n5. Calculate the preventive maintenance dates:\n   - Calculate the dates of preventive maintenance events on Machine-M1\n\n6. Calculate the time between preventive maintenance and breakdown:\n   - Calculate the time between each preventive maintenance event and the next breakdown event for Machine-M1\n\n7. Calculate the breakdown frequency after preventive maintenance:\n   - Calculate the number of breakdowns after preventive maintenance by counting the number of times Machine-M1 experienced a breakdown after a preventive maintenance event.\n\n8. Compare the breakdown frequencies before and after preventive maintenance:\n   - Calculate the breakdown frequency before preventive maintenance events on Machine-M1\n   - Calculate the breakdown frequency after preventive maintenance events on Machine-M1\n   - Compare the breakdown frequencies before and after preventive maintenance events to determine the impact of preventive maintenance on the breakdown frequency for Machine-M1.\n\n9. Calculate the average time between breakdowns:\n   - Calculate the average time between breakdowns for Machine-M1\n\n10. Calculate the average time between breakdowns after preventive maintenance:\n    - Calculate the average time between breakdowns for Machine-M1 after preventive maintenance events\n\n11. Compare the average breakdown intervals before and after preventive maintenance:\n    - Calculate the average breakdown interval before preventive maintenance events on Machine-M1\n    - Calculate the average breakdown interval after preventive maintenance events on Machine-M1\n    - Compare the average breakdown intervals before and after preventive maintenance events to determine the impact of preventive maintenance on the breakdown frequency for Machine-M1.\n\n12. Calculate the total preventive maintenance costs:\n    - Calculate the total preventive maintenance costs for Machine-M1\n\n13. Calculate the total breakdown costs:\n    - Calculate the total breakdown costs for Machine-M1\n\n14. Calculate the total costs saved due to preventive maintenance:\n    - Calculate the total costs saved due to preventive maintenance for Machine-M1\n\n15. Calculate the return on investment (ROI) for preventive maintenance:\n    - Calculate the ROI for preventive maintenance on Machine-M1\n\n16. Calculate the number of preventive maintenance events:\n    - Calculate the number of preventive maintenance events on Machine-M1\n\n17. Calculate the number of breakdown events:\n    - Calculate the number of breakdown events on Machine-M1\n\n18. Calculate the number of preventive maintenance events after breakdowns:\n    - Calculate the number of preventive maintenance events after breakdowns on Machine-M1\n\n19. Calculate the number of breakdown events after preventive maintenance:\n    - Calculate the number of breakdown events after preventive maintenance on Machine-M1\n\n20. Calculate the number of preventive maintenance events before breakdowns:\n    - Calculate the number of preventive maintenance events before breakdowns on Machine-M1\n\n21. Calculate the number of breakdown events before preventive maintenance:\n    - Calculate the number of breakdown events before preventive maintenance on Machine-M1\n\n22. Calculate the number of preventive maintenance events after breakdowns:\n    - Calculate the number of preventive maintenance events after breakdowns on Machine-M1\n\n23. Calculate the number of breakdown events after preventive maintenance:\n    - Calculate the number of breakdown events after preventive maintenance on Machine-M1\n\n24. Calculate the number of preventive maintenance events before breakdowns:\n    - Calculate the number of preventive maintenance events before breakdowns on Machine-M1\n\n25. Calculate the number of breakdown events before preventive maintenance:\n   ",
    "sql_response": "To determine the impact of preventive maintenance on the subsequent breakdown frequency for Machine-M1, we need to analyze the relationship between preventive maintenance and breakdown events. We can achieve this by calculating the breakdown frequency before and after preventive maintenance events for Machine-M1.\n\nHere's the SQL query to achieve this:\n\n```sql\nSELECT \n    COUNT(DISTINCT(maintenance_logs.Machine) AS Preventive_Maintenance_Breakdown_Frequency,\n    COUNT(DISTINCT(maintenance_logs.Machine) AS Breakdown_Frequency_Before_Preventive,\n    COUNT(DISTINCT(maintenance_logs.Machine) AS Breakdown_Frequency_After_Preventive\nFROM \n    maintenance_logs\nWHERE \n    maintenance_logs.Machine = 'Machine-M1'\nGROUP BY \n    maintenance_logs.Machine\nORDER BY \n    maintenance_logs.Machine;\n```\n\nThis query retrieves the breakdown frequency before and after preventive maintenance events for Machine-M1. It calculates the breakdown frequency before preventive maintenance by grouping the breakdown events before preventive maintenance and counting the distinct machines involved. Similarly, it calculates the breakdown frequency after preventive maintenance by grouping the breakdown events after preventive maintenance and counting the distinct machines involved. The results are ordered by Machine-M1. \n\nPlease note that this query assumes the `maintenance_logs` table contains records for both preventive and breakdown maintenance events for Machine-M1. If the table only contains breakdown events, you'll need to modify the query accordingly to include preventive maintenance records. ",
    "table_selection_response": "{\n  \"tables\": [\n    \"production_logs\",\n    \"maintenance_logs\"\n  ],\n  \"columns\": [\n    \"Machine\",\n    \"Downtime_Hours\",\n    \"Maintenance_Type\",\n    \"Breakdown_Date\",\n    \"Technician\",\n    \"Part_Replaced\",\n    \"Issue_Description\",\n    \"Machine\"\n  ]\n} ",
    "methodology_score": 65.0,
    "sql_score": 45.06703078450844,
    "table_column_score": 59.39393939393939,
    "response_quality_score": 87.63676619529724,
    "overall_score": 58.885622242592525,
    "methodology_details": {
      "method": "keyword_fallback",
      "overlap_count": 13,
      "expected_keyword_count": 20,
      "response_keyword_count": 90
    },
    "sql_details": {
      "table_match": 100.0,
      "column_match": 20.0,
      "aggregate_match": 0.0,
      "clause_match": 50.0,
      "fuzzy_score": 50.446871896722946,
      "overall_score": 45.06703078450844,
      "expected_tables": [
        "maintenance_logs"
      ],
      "generated_tables": [
        "maintenance_logs"
      ],
      "expected_columns": [
        "breakdown_date",
        "maintenance_date",
        "daystobreakdown",
        "machine"
      ],
      "generated_columns": [
        "maintenance_logs",
        "machine"
      ],
      "has_valid_sql": true
    },
    "table_column_details": {
      "overall_score": 59.39393939393939,
      "table_score": 66.66666666666666,
      "column_score": 54.54545454545454,
      "table_precision": 50.0,
      "table_recall": 100.0,
      "column_precision": 42.857142857142854,
      "column_recall": 75.0,
      "tables_correct": [
        "maintenance_logs"
      ],
      "tables_missing": [],
      "tables_extra": [
        "production_logs"
      ],
      "columns_correct": [
        "breakdown_date",
        "maintenance_type",
        "machine"
      ],
      "columns_missing": [
        "maintenance_date"
      ],
      "columns_extra": [
        "technician",
        "downtime_hours",
        "part_replaced",
        "issue_description"
      ],
      "expected_tables": [
        "maintenance_logs"
      ],
      "generated_tables": [
        "maintenance_logs",
        "production_logs"
      ],
      "expected_columns": [
        "breakdown_date",
        "maintenance_date",
        "maintenance_type",
        "machine"
      ],
      "generated_columns": [
        "part_replaced",
        "breakdown_date",
        "technician",
        "maintenance_type",
        "issue_description",
        "machine",
        "downtime_hours"
      ]
    },
    "total_latency_ms": 12363.233804702759,
    "total_tokens": 2997,
    "errors": [],
    "timestamp": "2025-11-30T13:07:18.097217"
  },
  {
    "question_id": "Medium_2",
    "question_text": "What is the total cost of maintenance for Machine-M2 in 2026?",
    "category": "Medium",
    "model_id": "allam-2-7b",
    "methodology_response": "To calculate the total cost of maintenance for Machine-M2 in 2026, we will follow these steps:\n\n1. Connect to the SQL database and select the necessary tables:\n   ```sql\n   SELECT * FROM inventory_logs\n   JOIN maintenance_logs ON inventory_logs.Machine = maintenance_logs.Machine\n   WHERE inventory_logs.Date >= '2026-01-01' AND inventory_logs.Date < '2027-01-01';\n   ```\n\n2. Filter the data for Machine-M2:\n   ```sql\n   WHERE maintenance_logs.Machine = 'Machine-M2';\n   ```\n\n3. Calculate the total maintenance hours for Machine-M2 in 2026:\n   ```sql\n   SUM(maintenance_logs.Downtime_Hours) AS Total_Maintenance_Hours;\n   ```\n\n4. Calculate the total maintenance cost for Machine-M2 in 2026:\n   ```sql\n   SUM(maintenance_logs.Cost_Rupees) AS Total_Maintenance_Cost;\n   ```\n\n5. Calculate the total maintenance hours and cost for all machines in 2026:\n   ```sql\n   SELECT SUM(Total_Maintenance_Hours) AS Total_Maintenance_Hours_All_Machines, SUM(Total_Maintenance_Cost) AS Total_Maintenance_Cost_All_Machines;\n   ```\n\n6. Calculate the average maintenance cost per machine in 2026:\n   ```sql\n   SELECT AVG(Total_Maintenance_Cost_All_Machines) AS Average_Maintenance_Cost_Per_Machine;\n   ```\n\n7. Calculate the total maintenance cost for Machine-M2 in 2026:\n   ```sql\n   SELECT SUM(Total_Maintenance_Cost) AS Total_Maintenance_Cost_Machine_M2;\n   ```\n\n8. Calculate the average maintenance cost per machine in 2026:\n   ```sql\n   SELECT AVG(Total_Maintenance_Cost_All_Machines) AS Average_Maintenance_Cost_Per_Machine;\n   ```\n\n9. Calculate the total maintenance cost for all machines in 2026:\n   ```sql\n   SELECT SUM(Total_Maintenance_Cost_All_Machines) AS Total_Maintenance_Cost_All_Machines;\n   ```\n\n10. Calculate the average maintenance cost per machine in 2026:\n    ```sql\n    SELECT AVG(Total_Maintenance_Cost_All_Machines) AS Average_Maintenance_Cost_Per_Machine;\n    ```\n\n11. Calculate the total maintenance cost for Machine-M2 in 2026:\n    ```sql\n    SELECT SUM(Total_Maintenance_Cost_Machine_M2) AS Total_Maintenance_Cost_Machine_M2;\n    ```\n\n12. Calculate the average maintenance cost per machine in 2026:\n    ```sql\n    SELECT AVG(Total_Maintenance_Cost_All_Machines) AS Average_Maintenance_Cost_Per_Machine;\n    ```\n\n13. Calculate the total maintenance cost for all machines in 2026:\n    ```sql\n    SELECT SUM(Total_Maintenance_Cost_All_Machines) AS Total_Maintenance_Cost_All_Machines;\n    ```\n\n14. Calculate the average maintenance cost per machine in 2026:\n    ```sql\n    SELECT AVG(Total_Maintenance_Cost_All_Machines) AS Average_Maintenance_Cost_Per_Machine;\n    ```\n\n15. Calculate the total maintenance cost for Machine-M2 in 2026:\n    ```sql\n    SELECT SUM(Total_Maint",
    "sql_response": "To find the total cost of maintenance for Machine-M2 in the year 2026, we need to join the `maintenance_logs` table with the `inventory_logs` table based on the `Machine` column and the `Year` column. Then, we need to filter the results for the year 2026 and sum the `Cost_Rupees` column. Finally, we should filter the results for Machine-M2.\n\nHere's the SQL query:\n\n```sql\nSELECT SUM(Cost_Rupees) AS Total_Maintenance_Cost\nFROM maintenance_logs ml\nJOIN inventory_logs il ON ml.Machine = il.Machine AND ml.Year = il.Year\nWHERE ml.Machine = 'Machine-M2' AND il.Year = '2026';\n```\n\nThis query joins the `maintenance_logs` and `inventory_logs` tables on the `Machine` and `Year` columns. Then, it filters the results for Machine-M2 and the year 2026. Finally, it calculates the sum of the `Cost_Rupees` column and displays the result as \"Total_Maintenance_Cost\". ",
    "table_selection_response": "{\n  \"tables\": [\n    \"maintenance_logs\"\n  ],\n  \"columns\": [\n    \"Machine\",\n    \"Cost_Rupees\"\n  ]\n} ",
    "methodology_score": 33.33333333333333,
    "sql_score": 54.95967741935483,
    "table_column_score": 88.0,
    "response_quality_score": 88.33365178108215,
    "overall_score": 60.06925227488241,
    "methodology_details": {
      "method": "keyword_fallback",
      "overlap_count": 3,
      "expected_keyword_count": 9,
      "response_keyword_count": 57
    },
    "sql_details": {
      "table_match": 50.0,
      "column_match": 50.0,
      "aggregate_match": 50.0,
      "clause_match": 75.0,
      "fuzzy_score": 58.06451612903225,
      "overall_score": 54.95967741935483,
      "expected_tables": [
        "maintenance_logs"
      ],
      "generated_tables": [
        "maintenance_logs",
        "inventory_logs"
      ],
      "expected_columns": [
        "cost_rupees",
        "machine"
      ],
      "generated_columns": [
        "cost_rupees"
      ],
      "has_valid_sql": true
    },
    "table_column_details": {
      "overall_score": 88.0,
      "table_score": 100.0,
      "column_score": 80.0,
      "table_precision": 100.0,
      "table_recall": 100.0,
      "column_precision": 100.0,
      "column_recall": 66.66666666666666,
      "tables_correct": [
        "maintenance_logs"
      ],
      "tables_missing": [],
      "tables_extra": [],
      "columns_correct": [
        "cost_rupees",
        "machine"
      ],
      "columns_missing": [
        "maintenance_date"
      ],
      "columns_extra": [],
      "expected_tables": [
        "maintenance_logs"
      ],
      "generated_tables": [
        "maintenance_logs"
      ],
      "expected_columns": [
        "cost_rupees",
        "maintenance_date",
        "machine"
      ],
      "generated_columns": [
        "cost_rupees",
        "machine"
      ]
    },
    "total_latency_ms": 11666.348218917847,
    "total_tokens": 2833,
    "errors": [],
    "timestamp": "2025-11-30T13:07:36.071046"
  },
  {
    "question_id": "Easy_32",
    "question_text": "What is the percentage of failed quantity for each product?",
    "category": "Easy",
    "model_id": "allam-2-7b",
    "methodology_response": "To answer the question about the percentage of failed quantity for each product, we will follow these steps:\n\n1. Connect to the database and select the necessary tables:\n   ```sql\n   SELECT production_logs, quality_control, inventory_logs\n   ```\n\n2. Filter the production_logs table to get the required data:\n   ```sql\n   WHERE production_logs.Product = 'Product of interest'\n   ```\n\n3. Filter the quality_control table to get the failed quantity:\n   ```sql\n   WHERE quality_control.Product = 'Product of interest'\n   ```\n\n4. Filter the inventory_logs table to get the material consumption:\n   ```sql\n   WHERE inventory_logs.Product = 'Product of interest'\n   ```\n\n5. Calculate the total quantity produced and consumed:\n   ```sql\n   SELECT SUM(production_logs.Actual_Qty) AS Total_Production, SUM(inventory_logs.Consumption_Kg) AS Total_Consumption\n   FROM production_logs\n   JOIN quality_control ON production_logs.Product = quality_control.Product\n   JOIN inventory_logs ON production_logs.Product = inventory_logs.Product\n   WHERE production_logs.Product = 'Product of interest'\n   ```\n\n6. Calculate the total quantity produced and consumed:\n   ```sql\n   SELECT SUM(production_logs.Actual_Qty) AS Total_Production, SUM(inventory_logs.Consumption_Kg) AS Total_Consumption\n   FROM production_logs\n   JOIN quality_control ON production_logs.Product = quality_control.Product\n   JOIN inventory_logs ON production_logs.Product = inventory_logs.Product\n   WHERE production_logs.Product = 'Product of interest'\n   ```\n\n7. Calculate the failed quantity:\n   ```sql\n   SELECT SUM(quality_control.Failed_Qty) AS Failed_Qty\n   FROM quality_control\n   WHERE quality_control.Product = 'Product of interest'\n   ```\n\n8. Calculate the percentage of failed quantity:\n   ```sql\n   SELECT (quality_control.Failed_Qty / (production_logs.Total_Production + quality_control.Failed_Qty) * 100 AS Failed_Percentage\n   FROM production_logs\n   JOIN quality_control ON production_logs.Product = quality_control.Product\n   WHERE production_logs.Product = 'Product of interest'\n   ```\n\n9. Combine the results from steps 7 and 8:\n   ```sql\n   SELECT quality_control.Failed_Qty, (quality_control.Failed_Qty / (production_logs.Total_Production + quality_control.Failed_Qty) * 100 AS Failed_Percentage\n   FROM production_logs\n   JOIN quality_control ON production_logs.Product = quality_control.Product\n   WHERE production_logs.Product = 'Product of interest'\n   ```\n\n10. Filter the result to get the percentage of failed quantity for each day:\n    ```sql\n    SELECT quality_control.Failed_Qty, (quality_control.Failed_Qty / (production_logs.Total_Production + quality_control.Failed_Qty) * 100 AS Failed_Percentage\n    FROM production_logs\n    JOIN quality_control ON production_logs.Product = quality_control.Product\n    WHERE production_logs.Product = 'Product of interest'\n    GROUP BY quality_control.Failed_Qty, production_logs.Date\n    ```\n\nThis SQL query will provide the percentage of failed quantity for each day, considering the production quantity and failed quantity for the given product. ",
    "sql_response": "To find the percentage of failed quantity for each product, we need to calculate the total failed quantity and the total quantity inspected for each product. Then, we can find the percentage of failed quantity. Here's the SQL query:\n\n```sql\nSELECT product, \n       (failed_qty / total_inspected_qty) * 100 AS failed_percentage\nFROM (\n  SELECT product,\n         SUM(CASE WHEN defect_type = 'Failed' THEN qty ELSE 0 END) AS failed_qty,\n         SUM(qty) AS total_inspected_qty\n  FROM quality_control\n  GROUP BY product\n) AS qc_data;\n```\n\nThis query uses a subquery to calculate the failed quantity and total inspected quantity for each product. Then, it calculates the percentage of failed quantity by dividing the failed quantity by the total inspected quantity and multiplying by 100. ",
    "table_selection_response": "{\n  \"tables\": [\n    \"quality_control\"\n  ],\n  \"columns\": [\n    \"Product\",\n    \"Failed_Qty\"\n  ]\n} ",
    "methodology_score": 53.84615384615385,
    "sql_score": 62.88666666666666,
    "table_column_score": 88.0,
    "response_quality_score": 88.9127459526062,
    "overall_score": 69.05545408244011,
    "methodology_details": {
      "method": "keyword_fallback",
      "overlap_count": 7,
      "expected_keyword_count": 13,
      "response_keyword_count": 71
    },
    "sql_details": {
      "table_match": 100.0,
      "column_match": 16.666666666666664,
      "aggregate_match": 50.0,
      "clause_match": 100.0,
      "fuzzy_score": 58.133333333333326,
      "overall_score": 62.88666666666666,
      "expected_tables": [
        "quality_control"
      ],
      "generated_tables": [
        "quality_control"
      ],
      "expected_columns": [
        "product",
        "0 / inspected_qty",
        "failed_qty"
      ],
      "generated_columns": [
        "product",
        "case when defect_type = failed then qty else 0 end",
        "qty",
        "failed_qty / total_inspected_qty * 100"
      ],
      "has_valid_sql": true
    },
    "table_column_details": {
      "overall_score": 88.0,
      "table_score": 100.0,
      "column_score": 80.0,
      "table_precision": 100.0,
      "table_recall": 100.0,
      "column_precision": 100.0,
      "column_recall": 66.66666666666666,
      "tables_correct": [
        "quality_control"
      ],
      "tables_missing": [],
      "tables_extra": [],
      "columns_correct": [
        "product",
        "failed_qty"
      ],
      "columns_missing": [
        "inspected_qty"
      ],
      "columns_extra": [],
      "expected_tables": [
        "quality_control"
      ],
      "generated_tables": [
        "quality_control"
      ],
      "expected_columns": [
        "product",
        "inspected_qty",
        "failed_qty"
      ],
      "generated_columns": [
        "product",
        "failed_qty"
      ]
    },
    "total_latency_ms": 11087.254047393799,
    "total_tokens": 2667,
    "errors": [],
    "timestamp": "2025-11-30T13:07:53.472492"
  },
  {
    "question_id": "Easy_29",
    "question_text": "What is the maximum downtime hours recorded for any breakdown?",
    "category": "Easy",
    "model_id": "allam-2-7b",
    "methodology_response": "To answer the question about the maximum downtime hours recorded for any breakdown, we will follow these steps:\n\n1. Connect to the database and select the required tables:\n   ```sql\n   SELECT * FROM production_logs\n   JOIN maintenance_logs ON production_logs.Machine = maintenance_logs.Machine\n   JOIN inventory_logs ON production_logs.Machine = inventory_logs.Machine\n   ```\n\n2. Filter the data based on the breakdown events:\n   ```sql\n   WHERE maintenance_logs.Maintenance_Type LIKE 'Breakdown%'\n   ```\n\n3. Calculate the total downtime hours for each breakdown event:\n   ```sql\n   SUM(production_logs.Downtime_Hours) AS Downtime_Hours\n   ```\n\n4. Group the data by breakdown events:\n   ```sql\n   GROUP BY maintenance_logs.Machine\n   ```\n\n5. Find the maximum downtime hours for all breakdown events:\n   ```sql\n   MAX(Downtime_Hours) AS Max_Downtime_Hours\n   ```\n\n6. Display the result with the breakdown event and its corresponding maximum downtime hours:\n   ```sql\n   SELECT maintenance_logs.Machine AS Machine, Max(Downtime_Hours) AS Max_Downtime_Hours\n   ```\n\nThe final SQL query will look like this:\n```sql\nSELECT maintenance_logs.Machine AS Machine, MAX(production_logs.Downtime_Hours) AS Max_Downtime_Hours\nFROM production_logs\nJOIN maintenance_logs ON production_logs.Machine = maintenance_logs.Machine\nJOIN inventory_logs ON production_logs.Machine = inventory_logs.Machine\nWHERE maintenance_logs.Maintenance_Type LIKE 'Breakdown%'\nGROUP BY maintenance_logs.Machine\n```\n\nThis query will retrieve the maximum downtime hours for all breakdown events by joining the required tables, filtering for breakdown maintenance types, grouping by machine, and calculating the maximum downtime hours. ",
    "sql_response": "To find the maximum downtime hours recorded for any breakdown, we can use a combination of JOINs and aggregate functions in SQL. Here's the query:\n\n```sql\nSELECT maintenance_logs.Machine, MAX(maintenance_logs.Downtime_Hours) AS Max_Downtime_Hours\nFROM maintenance_logs\nJOIN inventory_logs ON maintenance_logs.Machine = inventory_logs.Material_Code\nGROUP BY maintenance_logs.Machine;\n```\n\nThis query joins the `maintenance_logs` and `inventory_logs` tables on the `Machine` and `Material_Code` columns respectively. Then, it groups the result by `Machine` and calculates the maximum downtime hours using the `MAX()` function. The result will show the machines with the maximum downtime hours along with their corresponding values. ",
    "table_selection_response": "{\n  \"tables\": [\n    \"production_logs\",\n    \"maintenance_logs\"\n  ],\n  \"columns\": [\n    \"Downtime_Hours\",\n    \"Breakdown_Date\",\n    \"Technician\"\n  ]\n} ",
    "methodology_score": 55.55555555555556,
    "sql_score": 51.524193548387096,
    "table_column_score": 50.66666666666666,
    "response_quality_score": 89.40556907653809,
    "overall_score": 56.30735798292262,
    "methodology_details": {
      "method": "keyword_fallback",
      "overlap_count": 5,
      "expected_keyword_count": 9,
      "response_keyword_count": 70
    },
    "sql_details": {
      "table_match": 50.0,
      "column_match": 25.0,
      "aggregate_match": 100.0,
      "clause_match": 40.0,
      "fuzzy_score": 45.16129032258065,
      "overall_score": 51.524193548387096,
      "expected_tables": [
        "maintenance_logs"
      ],
      "generated_tables": [
        "maintenance_logs",
        "inventory_logs"
      ],
      "expected_columns": [
        "downtime_hours",
        "maintenance_type"
      ],
      "generated_columns": [
        "maintenance_logs",
        "downtime_hours",
        "machine"
      ],
      "has_valid_sql": true
    },
    "table_column_details": {
      "overall_score": 50.66666666666666,
      "table_score": 66.66666666666666,
      "column_score": 40.0,
      "table_precision": 50.0,
      "table_recall": 100.0,
      "column_precision": 33.33333333333333,
      "column_recall": 50.0,
      "tables_correct": [
        "maintenance_logs"
      ],
      "tables_missing": [],
      "tables_extra": [
        "production_logs"
      ],
      "columns_correct": [
        "downtime_hours"
      ],
      "columns_missing": [
        "maintenance_type"
      ],
      "columns_extra": [
        "breakdown_date",
        "technician"
      ],
      "expected_tables": [
        "maintenance_logs"
      ],
      "generated_tables": [
        "maintenance_logs",
        "production_logs"
      ],
      "expected_columns": [
        "downtime_hours",
        "maintenance_type"
      ],
      "generated_columns": [
        "breakdown_date",
        "technician",
        "downtime_hours"
      ]
    },
    "total_latency_ms": 10594.430923461914,
    "total_tokens": 2241,
    "errors": [],
    "timestamp": "2025-11-30T13:08:10.583860"
  },
  {
    "question_id": "Easy_18",
    "question_text": "How many preventive maintenance activities were performed on Machine-M2 this year?",
    "category": "Easy",
    "model_id": "allam-2-7b",
    "methodology_response": "To answer the question about the number of preventive maintenance activities performed on Machine-M2 this year, we will follow these steps:\n\n1. Connect to the SQL database and select the necessary tables:\n   ```sql\n   SELECT * FROM production_logs;\n   SELECT * FROM quality_control;\n   SELECT * FROM inventory_logs;\n   SELECT * FROM maintenance_logs;\n   ```\n2. Filter the data for the desired year:\n   ```sql\n   SELECT * FROM production_logs WHERE production_logs.Date >= 'YYYY-01-01' AND production_logs.Date < 'YYYY-12-31';\n   SELECT * FROM quality_control WHERE quality_control.Inspection_Date >= 'YYYY-01-01' AND quality_control.Inspection_Date < 'YYYY-12-31';\n   SELECT * FROM inventory_logs WHERE inventory_logs.Date >= 'YYYY-01-01' AND inventory_logs.Date < 'YYYY-12-31';\n   SELECT * FROM maintenance_logs WHERE maintenance_logs.Maintenance_Date >= 'YYYY-01-01' AND maintenance_logs.Maintenance_Date < 'YYYY-12-31';\n   ```\n3. Filter the data for Machine-M2:\n   ```sql\n   SELECT maintenance_logs.Machine_Name, COUNT(maintenance_logs.Machine_Name) AS Maintenance_Activities\n   FROM maintenance_logs\n   WHERE maintenance_logs.Machine_Name = 'Machine-M2'\n   GROUP BY maintenance_logs.Machine_Name;\n   ```\n4. Filter the data for preventive maintenance activities:\n   ```sql\n   SELECT maintenance_logs.Machine_Name, COUNT(maintenance_logs.Machine_Name) AS Preventive_Maintenance_Activities\n   FROM maintenance_logs\n   WHERE maintenance_logs.Maintenance_Type = 'Preventive Maintenance'\n   GROUP BY maintenance_logs.Machine_Name;\n   ```\n5. Combine the data from steps 3 and 4 to get the total preventive maintenance activities performed on Machine-M2:\n   ```sql\n   SELECT maintenance_logs.Machine_Name, SUM(Preventive_Maintenance_Activities) AS Total_Preventive_Maintenance_Activities\n   FROM (\n     SELECT maintenance_logs.Machine_Name, COUNT(maintenance_logs.Machine_Name) AS Preventive_Maintenance_Activities\n     FROM maintenance_logs\n     WHERE maintenance_logs.Maintenance_Type = 'Preventive Maintenance'\n     GROUP BY maintenance_logs.Machine_Name\n   ) AS Preventive_Maintenance_Activities_Table\n   JOIN (\n     SELECT maintenance_logs.Machine_Name, COUNT(maintenance_logs.Machine_Name) AS Maintenance_Activities\n     FROM maintenance_logs\n     GROUP BY maintenance_logs.Machine_Name\n   ) AS Maintenance_Activities_Table\n   ON Maintenance_Activities_Table.Machine_Name = Preventive_Maintenance_Activities_Table.Machine_Name;\n   ```\n6. Filter the result to get the total preventive maintenance activities performed on Machine-M2:\n   ```sql\n   SELECT Maintenance_Activities_Table.Machine_Name, SUM(Maintenance_Activities_Table.Maintenance_Activities) AS Total_Preventive_Maintenance_Activities\n   FROM Maintenance_Activities_Table\n   WHERE Maintenance_Activities_Table.Machine_Name = 'Machine-M2';\n   ```\n7. Combine the results from steps 5 and 6 to get the total preventive maintenance activities performed on Machine-M2:\n   ```sql\n   SELECT Maintenance_Activities_Table.Machine_Name, SUM(Preventive_Maintenance_Act",
    "sql_response": "To find the number of preventive maintenance activities performed on Machine-M2 this year, we can use the following SQL query:\n\n```sql\nSELECT COUNT(*)\nFROM maintenance_logs\nWHERE Machine = 'Machine-M2'\n  AND Maintenance_Type = 'Preventive'\n  AND Date >= DATEADD(year, DATEDIFF(year, 0, GETDATE()), 0);\n```\n\nThis query selects the count of all rows from the `maintenance_logs` table where the machine is 'Machine-M2', the maintenance type is 'Preventive', and the date is greater than or equal to the current year minus one year (`GETDATE()` function returns the current date and time, and `DATEDIFF(year, 0, GETDATE())` returns the number of years since January 1, 1900). ",
    "table_selection_response": "{\n  \"tables\": [\n    \"maintenance_logs\"\n  ],\n  \"columns\": [\n    \"Machine\",\n    \"Maintenance_Type\"\n  ]\n} ",
    "methodology_score": 41.66666666666667,
    "sql_score": 95.92537313432835,
    "table_column_score": 88.0,
    "response_quality_score": 89.10840344429016,
    "overall_score": 76.98472094144394,
    "methodology_details": {
      "method": "keyword_fallback",
      "overlap_count": 5,
      "expected_keyword_count": 12,
      "response_keyword_count": 71
    },
    "sql_details": {
      "table_match": 100.0,
      "column_match": 100.0,
      "aggregate_match": 100.0,
      "clause_match": 100.0,
      "fuzzy_score": 72.83582089552239,
      "overall_score": 95.92537313432835,
      "expected_tables": [
        "maintenance_logs"
      ],
      "generated_tables": [
        "maintenance_logs"
      ],
      "expected_columns": [
        "machine"
      ],
      "generated_columns": [
        "machine"
      ],
      "has_valid_sql": true
    },
    "table_column_details": {
      "overall_score": 88.0,
      "table_score": 100.0,
      "column_score": 80.0,
      "table_precision": 100.0,
      "table_recall": 100.0,
      "column_precision": 100.0,
      "column_recall": 66.66666666666666,
      "tables_correct": [
        "maintenance_logs"
      ],
      "tables_missing": [],
      "tables_extra": [],
      "columns_correct": [
        "maintenance_type",
        "machine"
      ],
      "columns_missing": [
        "maintenance_date"
      ],
      "columns_extra": [],
      "expected_tables": [
        "maintenance_logs"
      ],
      "generated_tables": [
        "maintenance_logs"
      ],
      "expected_columns": [
        "maintenance_date",
        "maintenance_type",
        "machine"
      ],
      "generated_columns": [
        "maintenance_type",
        "machine"
      ]
    },
    "total_latency_ms": 10891.596555709839,
    "total_tokens": 2725,
    "errors": [],
    "timestamp": "2025-11-30T13:08:27.737213"
  },
  {
    "question_id": "Complex_32",
    "question_text": "Which machine has the highest average downtime due to breakdowns in the last quarter, and what is the total cost associated with those breakdowns?",
    "category": "Complex",
    "model_id": "allam-2-7b",
    "methodology_response": "To answer the question about the machine with the highest average downtime due to breakdowns in the last quarter and the total cost associated with those breakdowns, we will follow these steps:\n\n1. Connect to the database and select the required tables:\n   - Production logs (production_logs) to get machine-related data\n   - Maintenance logs (maintenance_logs) to get breakdown-related data\n   - Quality control (quality_control) to get product-related data\n\n2. Filter the data for the last quarter:\n   - Production logs: Select rows where Date >= DATEADD(quarter, -1, GETDATE()) and Date < DATEADD(quarter, -1, GETDATE())\n   - Maintenance logs: Select rows where Maintenance_Date >= DATEADD(quarter, -1, GETDATE()) and Maintenance_Date < DATEADD(quarter, -1, GETDATE())\n   - Quality control: Select rows where Inspection_Date >= DATEADD(quarter, -1, GETDATE()) and Inspection_Date < DATEADD(quarter, -1, GETDATE())\n\n3. Calculate the total downtime for each machine due to breakdowns:\n   - Maintenance logs: Sum Downtime_Hours for each machine\n\n4. Calculate the average downtime for each machine due to breakdowns:\n   - Maintenance logs: Calculate the average Downtime_Hours for each machine\n\n5. Filter the data for breakdowns only:\n   - Maintenance logs: Select rows where Maintenance_Type = 'Breakdown'\n\n6. Calculate the total downtime for each machine due to breakdowns:\n   - Maintenance logs (filtered data): Sum Downtime_Hours for each machine\n\n7. Calculate the average downtime for each machine due to breakdowns:\n   - Maintenance logs (filtered data): Calculate the average Downtime_Hours for each machine\n\n8. Filter the data for breakdowns and calculate the average downtime:\n   - Maintenance logs (filtered data): Select rows where Maintenance_Type = 'Breakdown' and Date >= DATEADD(quarter, -1, GETDATE()) and Date < DATEADD(quarter, -1, GETDATE())\n\n9. Calculate the total downtime for each machine due to breakdowns:\n   - Maintenance logs (filtered data): Sum Downtime_Hours for each machine\n\n10. Calculate the average downtime for each machine due to breakdowns:\n    - Maintenance logs (filtered data): Calculate the average Downtime_Hours for each machine\n\n11. Calculate the total downtime for each machine due to breakdowns and in the last quarter:\n    - Maintenance logs (filtered data): Sum Downtime_Hours for each machine\n\n12. Calculate the average downtime for each machine due to breakdowns in the last quarter:\n    - Maintenance logs (filtered data): Calculate the average Downtime_Hours for each machine\n\n13. Calculate the total downtime for each machine due to breakdowns in the last quarter:\n    - Maintenance logs (filtered data): Sum Downtime_Hours for each machine\n\n14. Calculate the average downtime for each machine due to breakdowns in the last quarter:\n    - Maintenance logs (filtered data): Calculate the average Downtime_Hours for each machine\n\n15. Calculate the total downtime for all machines due to breakdowns in the last quarter:\n    - Maintenance logs (filtered data): Sum Downtime_Hours for all machines\n\n16. Calculate the average downtime for all machines due to breakdowns in the last quarter:\n    - Maintenance logs (filtered data): Calculate the average Downtime_Hours for all machines\n\n17. Calculate the total downtime for each machine due to breakdowns in the last quarter:\n    - Maintenance logs (filtered data): Sum Downtime_Hours for each machine\n\n18. Calculate the average downtime for each machine due to breakdowns in the last quarter:\n    - Maintenance logs (filtered data): Calculate the average Downtime_Hours for each machine\n\n19. Find the machine with the highest average downtime due to breakdowns in the last quarter:\n    - Maintenance logs (filtered data): Select the machine with the highest average Downtime_Hours\n\n20. Calculate the total downtime for the identified machine due to breakdowns in",
    "sql_response": "To find the machine with the highest average downtime due to breakdowns in the last quarter and the total cost associated with those breakdowns, we can use the following SQL query:\n\n```sql\nSELECT \n    Machine, \n    AVG(Downtime_Hours) AS Avg_Downtime, \n    SUM(CASE WHEN Maintenance_Type = 'Breakdown' THEN Cost_Rupees ELSE 0 END) AS Total_Breakdown_Cost\nFROM \n    maintenance_logs\nWHERE \n    Maintenance_Type IN ('Breakdown')\n    AND Maintenance_Date >= DATEADD(QUARTER, DATEDIFF(QUARTER, 0, GETDATE()) - 1, 0)\nGROUP BY \n    Machine\nORDER BY \n    Avg_Downtime DESC;\n```\n\nThis query will calculate the average downtime (`AVG(Downtime_Hours)`) and the total breakdown cost (`SUM(CASE WHEN Maintenance_Type = 'Breakdown' THEN Cost_Rupees ELSE 0 END)`) for each machine. It will then group the results by machine and sort them in descending order based on the average downtime. The result will show the machine with the highest average downtime and the corresponding breakdown cost. \n\nNote: Make sure to replace `'Breakdown'` with the actual Maintenance_Type column name if it has a different name in your database. Also, adjust the `DATEDIFF` function according to your date format and data type of the Maintenance_Date column. ",
    "table_selection_response": "{\n  \"tables\": [\n    \"production_logs\",\n    \"maintenance_logs\"\n  ],\n  \"columns\": [\n    \"Machine\",\n    \"Downtime_Hours\",\n    \"Breakdown_Date\",\n    \"Technician\",\n    \"Cost_Rupees\"\n  ]\n} ",
    "methodology_score": 55.172413793103445,
    "sql_score": 73.83849557522123,
    "table_column_score": 62.66666666666667,
    "response_quality_score": 87.21041655540466,
    "overall_score": 66.78290591146559,
    "methodology_details": {
      "method": "keyword_fallback",
      "overlap_count": 16,
      "expected_keyword_count": 29,
      "response_keyword_count": 75
    },
    "sql_details": {
      "table_match": 100.0,
      "column_match": 25.0,
      "aggregate_match": 100.0,
      "clause_match": 83.33333333333334,
      "fuzzy_score": 67.25663716814158,
      "overall_score": 73.83849557522123,
      "expected_tables": [
        "maintenance_logs"
      ],
      "generated_tables": [
        "maintenance_logs"
      ],
      "expected_columns": [
        "totalcost",
        "avgdowntime",
        "maintenance_type",
        "machine",
        "cost_rupees",
        "downtime_hours"
      ],
      "generated_columns": [
        "avg_downtime",
        "case when maintenance_type = breakdown then cost_rupees else 0 end",
        "downtime_hours",
        "machine"
      ],
      "has_valid_sql": true
    },
    "table_column_details": {
      "overall_score": 62.66666666666667,
      "table_score": 66.66666666666666,
      "column_score": 60.0,
      "table_precision": 50.0,
      "table_recall": 100.0,
      "column_precision": 60.0,
      "column_recall": 60.0,
      "tables_correct": [
        "maintenance_logs"
      ],
      "tables_missing": [],
      "tables_extra": [
        "production_logs"
      ],
      "columns_correct": [
        "cost_rupees",
        "downtime_hours",
        "machine"
      ],
      "columns_missing": [
        "maintenance_date",
        "maintenance_type"
      ],
      "columns_extra": [
        "breakdown_date",
        "technician"
      ],
      "expected_tables": [
        "maintenance_logs"
      ],
      "generated_tables": [
        "maintenance_logs",
        "production_logs"
      ],
      "expected_columns": [
        "maintenance_date",
        "maintenance_type",
        "machine",
        "cost_rupees",
        "downtime_hours"
      ],
      "generated_columns": [
        "breakdown_date",
        "technician",
        "machine",
        "cost_rupees",
        "downtime_hours"
      ]
    },
    "total_latency_ms": 12789.583444595337,
    "total_tokens": 2990,
    "errors": [],
    "timestamp": "2025-11-30T13:08:46.784787"
  },
  {
    "question_id": "Easy_14",
    "question_text": "What is the total wastage in kilograms for 'Steel Sheet 101' this year?",
    "category": "Easy",
    "model_id": "allam-2-7b",
    "methodology_response": "To calculate the total wastage in kilograms for 'Steel Sheet 101' this year, we will follow these steps:\n\n1. Connect to the SQL database and select the necessary tables:\n   ```sql\n   SELECT inventory_logs, maintenance_logs, production_logs, quality_control\n   ```\n\n2. Filter the inventory_logs table for the desired material code and year:\n   ```sql\n   SELECT inventory_logs.*\n   WHERE inventory_logs.Material_Code = 'Steel Sheet 101' AND inventory_logs.Date >= DATEADD(year, -1, GETDATE())\n   ```\n\n3. Filter the maintenance_logs table for the material code and year:\n   ```sql\n   SELECT maintenance_logs.*\n   WHERE maintenance_logs.Material_Code = 'Steel Sheet 101' AND maintenance_logs.Date >= DATEADD(year, -1, GETDATE())\n   ```\n\n4. Filter the production_logs table for the material code, year, and shift:\n   ```sql\n   SELECT production_logs.*\n   WHERE production_logs.Material_Code = 'Steel Sheet 101' AND production_logs.Date >= DATEADD(year, -1, GETDATE()) AND production_logs.Shift = 'Shift 1'\n   ```\n\n5. Filter the quality_control table for the material code, batch ID, and year:\n   ```sql\n   SELECT quality_control.*\n   WHERE quality_control.Material_Code = 'Steel Sheet 101' AND quality_control.Inspection_Date >= DATEADD(year, -1, GETDATE()) AND quality_control.Batch_ID IS NOT NULL\n   ```\n\n6. Calculate the total consumption (Wastage) by subtracting the opening stock and closing stock from the total consumption:\n   ```sql\n   SELECT SUM(consumption) AS Total_Wastage\n   FROM\n   (\n       SELECT SUM(Closing_Stock + Consumption - Opening_Stock) AS consumption\n       FROM\n       (\n           SELECT SUM(consumption) AS Opening_Stock\n           FROM\n           (\n               SELECT SUM(consumption) AS Consumption\n               FROM production_logs\n               WHERE Material_Code = 'Steel Sheet 101' AND Date >= DATEADD(year, -1, GETDATE()) AND Shift = 'Shift 1'\n       ) AS Production_Logs_Shift_1\n   ) AS Production_Logs_Shift_1_Consumption\n   WHERE Material_Code = 'Steel Sheel 101' AND Inspection_Date >= DATEADD(year, -1, GETDATE()) AND Batch_ID IS NOT NULL\n   ) AS Production_Control_Batch_1\n   ) AS Production_Control_Batch_1_Consumption\n   WHERE Material_Code = 'Steel Sheet 101' AND Inspection_Date >= DATEADD(year, -1, GETDATE()) AND Batch_ID IS NOT NULL\n   ) AS Production_Control_Batch_1_Consumption\n   ) AS Production_Control_Batch_1_Consumption_Wastage\n   WHERE Material_Code = 'Steel Sheet 101' AND Inspection_Date >= DATEADD(year, -1, GETDATE()) AND Batch_ID IS NOT NULL\n   ) AS Production_Control_Batch_1_Consumption_Wastage\n   ) AS Production_Control_Batch_1_Consumption_Wastage\n   WHERE Material_Code = 'Steel Sheet 101' AND Inspection_Date >= DATEADD(year, -1, GETDATE()) AND Batch_ID IS NOT NULL\n   ) AS Production_Control_",
    "sql_response": "To find the total wastage in kilograms for 'Steel Sheet 101' this year, we can use the following SQL query:\n\n```sql\nSELECT SUM(Consumption_Kg) AS Total_Wastage\nFROM inventory_logs\nWHERE Material_Code = 'Steel-101'\nAND Date >= DATEADD(year, DATEDIFF(year, 0, GETDATE()), 0);\n```\n\nExplanation:\n1. We use the `SUM()` function to calculate the total consumption of 'Steel Sheet 101'.\n2. The `FROM` clause specifies the table `inventory_logs` from which we want to retrieve the data.\n3. The `WHERE` clause filters the data to only include records where the material code is 'Steel-101' and the date is greater than or equal to the current year minus one year (`DATEADD(year, DATEDIFF(year, 0, GETDATE()), 0)`). This ensures we get data for the current year and the previous year.\n4. The `AS` keyword is used to give an alias to the result column, named 'Total_Wastage'. ",
    "table_selection_response": "{\n  \"tables\": [\n    \"inventory_logs\"\n  ],\n  \"columns\": [\n    \"Wastage_Kg\"\n  ]\n} ",
    "methodology_score": 46.15384615384615,
    "sql_score": 58.501628664495115,
    "table_column_score": 70.0,
    "response_quality_score": 88.9193172454834,
    "overall_score": 60.71365560327548,
    "methodology_details": {
      "method": "keyword_fallback",
      "overlap_count": 6,
      "expected_keyword_count": 13,
      "response_keyword_count": 82
    },
    "sql_details": {
      "table_match": 100.0,
      "column_match": 0.0,
      "aggregate_match": 50.0,
      "clause_match": 100.0,
      "fuzzy_score": 56.67752442996743,
      "overall_score": 58.501628664495115,
      "expected_tables": [
        "inventory_logs"
      ],
      "generated_tables": [
        "inventory_logs"
      ],
      "expected_columns": [
        "wastage_kg"
      ],
      "generated_columns": [
        "material_code",
        "consumption_kg"
      ],
      "has_valid_sql": true
    },
    "table_column_details": {
      "overall_score": 70.0,
      "table_score": 100.0,
      "column_score": 50.0,
      "table_precision": 100.0,
      "table_recall": 100.0,
      "column_precision": 100.0,
      "column_recall": 33.33333333333333,
      "tables_correct": [
        "inventory_logs"
      ],
      "tables_missing": [],
      "tables_extra": [],
      "columns_correct": [
        "wastage_kg"
      ],
      "columns_missing": [
        "material_name",
        "date"
      ],
      "columns_extra": [],
      "expected_tables": [
        "inventory_logs"
      ],
      "generated_tables": [
        "inventory_logs"
      ],
      "expected_columns": [
        "wastage_kg",
        "material_name",
        "date"
      ],
      "generated_columns": [
        "wastage_kg"
      ]
    },
    "total_latency_ms": 11080.682754516602,
    "total_tokens": 2818,
    "errors": [],
    "timestamp": "2025-11-30T13:09:04.787006"
  },
  {
    "question_id": "Complex_18",
    "question_text": "What is the average unit cost of materials purchased from each supplier, and which supplier has the lowest average cost?",
    "category": "Complex",
    "model_id": "allam-2-7b",
    "methodology_response": "To answer the question about the average unit cost of materials purchased from each supplier and identify the supplier with the lowest average cost, we will follow these steps:\n\n1. Connect to the database and select the necessary tables:\n   - Production of the tables: `production_logs`, `inventory_logs`, `maintenance_logs`\n   - Quality Control of the table: `quality_control`\n   - Supplier information: None, as we have the supplier information in a separate database or file\n\n2. Filter the data based on the manufacturing date range:\n   - Select the manufacturing dates from the `production_logs` table where the `production_logs.Date` is within the given date range.\n\n3. Filter the inventory data based on the manufacturing date range:\n   - Select the inventory data from the `inventory_logs` table where the `inventory_logs.Date` is within the given date range.\n\n4. Filter the quality control data based on the manufacturing date range:\n   - Select the quality control data from the `quality_control` table where the `quality_control.Inspection_Date` is within the given date range.\n\n5. Calculate the total consumption of each material:\n   - Join the filtered inventory data with the filtered quality control data on the common columns `inventory_logs.Material_Code` and `quality_control.Product`.\n   - Calculate the total consumption of each material by summing the `inventory_logs.Consumption_Kg` and `quality_control.Consumption_Kg` columns.\n\n6. Calculate the total cost of each material:\n   - Multiply the total consumption of each material by the unit cost (`inventory_logs.Unit_Cost_Rupees` or `quality_control.Unit_Cost_Rupees`).\n\n7. Calculate the average cost per unit for each material:\n   - Group the data by `Material_Code` and calculate the average of the total cost per unit.\n\n8. Calculate the total cost of each supplier:\n   - Join the calculated average cost per unit data with the supplier data on the common column `Material_Code`.\n   - Sum the total cost of each supplier by grouping the data on `Supplier_Code`.\n\n9. Calculate the average cost per unit for each supplier:\n   - Group the data by `Supplier_Code` and calculate the average of the total cost per unit.\n\n10. Calculate the total cost of each supplier for a specific date range:\n    - Join the calculated average cost per unit data with the filtered inventory data on the common columns `inventory_logs.Material_Code` and `quality_control.Product`.\n    - Sum the total cost of each supplier for the specific date range by grouping the data on `Supplier_Code` and `Date`.\n\n11. Calculate the average cost per unit for each supplier for a specific date range:\n    - Group the data by `Supplier_Code` and `Date`.\n    - Calculate the average of the total cost per unit for each supplier on the specific date range.\n\n12. Calculate the total cost of each supplier for a specific date range:\n    - Join the calculated average cost per unit data with the filtered inventory data on the common columns `inventory_logs.Material_Code` and `quality_control.Product`.\n    - Sum the total cost of each supplier for the specific date range by grouping the data on `Supplier_Code` and `Date`.\n\n13. Calculate the total cost of each supplier for a specific date range:\n    - Join the calculated total cost data with the filtered inventory data on the common columns `inventory_logs.Material_Code` and `quality_control.Product`.\n    - Sum the total cost of each supplier for the specific date range by grouping the data on `Supplier_Code` and `Date`.\n\n14. Calculate the average cost per unit for each supplier for a specific date range:\n    - Join the calculated total cost data with the filtered inventory data on the common columns `inventory_logs.Material_Code` and `quality_control.Product`.\n    - Group the data by `Supplier_Code` and `Date`.\n    - Calculate the average of the total cost per unit for each supplier on the specific date range.\n\n15.",
    "sql_response": "To find the average unit cost of materials purchased from each supplier and identify the supplier with the lowest average cost, we can use the following SQL query:\n\n```sql\nSELECT s.Supplier, AVG(il.Unit_Cost_Rupees) AS Average_Cost\nFROM inventory_logs il\nJOIN inventory i ON il.Material_Code = i.Material_Code\nJOIN suppliers s ON i.Supplier = s.Supplier_Name\nGROUP BY s.Supplier;\n```\n\nThis query joins the `inventory_logs`, `inventory`, and `suppliers` tables. We calculate the average unit cost by grouping the results by the supplier and using the `AVG` function. The result will include the supplier's name and the average unit cost. ",
    "table_selection_response": "{\n  \"tables\": [\n    \"inventory_logs\"\n  ],\n  \"columns\": [\n    \"Supplier\",\n    \"Unit_Cost_Rupees\"\n  ]\n} ",
    "methodology_score": 50.0,
    "sql_score": 72.97583081570997,
    "table_column_score": 100.0,
    "response_quality_score": 87.39931106567383,
    "overall_score": 74.28147189206587,
    "methodology_details": {
      "method": "keyword_fallback",
      "overlap_count": 8,
      "expected_keyword_count": 16,
      "response_keyword_count": 91
    },
    "sql_details": {
      "table_match": 100.0,
      "column_match": 50.0,
      "aggregate_match": 100.0,
      "clause_match": 50.0,
      "fuzzy_score": 53.17220543806647,
      "overall_score": 72.97583081570997,
      "expected_tables": [
        "inventory_logs"
      ],
      "generated_tables": [
        "inventory_logs"
      ],
      "expected_columns": [
        "unit_cost_rupees",
        "supplier",
        "avgunitcost"
      ],
      "generated_columns": [
        "s",
        "unit_cost_rupees",
        "supplier"
      ],
      "has_valid_sql": true
    },
    "table_column_details": {
      "overall_score": 100.0,
      "table_score": 100.0,
      "column_score": 100.0,
      "table_precision": 100.0,
      "table_recall": 100.0,
      "column_precision": 100.0,
      "column_recall": 100.0,
      "tables_correct": [
        "inventory_logs"
      ],
      "tables_missing": [],
      "tables_extra": [],
      "columns_correct": [
        "unit_cost_rupees",
        "supplier"
      ],
      "columns_missing": [],
      "columns_extra": [],
      "expected_tables": [
        "inventory_logs"
      ],
      "generated_tables": [
        "inventory_logs"
      ],
      "expected_columns": [
        "unit_cost_rupees",
        "supplier"
      ],
      "generated_columns": [
        "unit_cost_rupees",
        "supplier"
      ]
    },
    "total_latency_ms": 12600.688934326172,
    "total_tokens": 2728,
    "errors": [],
    "timestamp": "2025-11-30T13:09:23.918365"
  },
  {
    "question_id": "Complex_1",
    "question_text": "What is the average downtime (in minutes) per shift for each machine in the last quarter?",
    "category": "Complex",
    "model_id": "allam-2-7b",
    "methodology_response": "To answer the question about the average downtime per shift for each machine in the last quarter, we will follow these steps:\n\n1. Connect to the SQL database and select the required tables:\n```sql\nSELECT production_logs, quality_control, maintenance_logs, inventory_logs\n```\n2. Filter the data for the last quarter (let's assume the quarter starts from January 1st):\n```sql\nWHERE production_logs.Date >= DATEADD(quarter, -1, GETDATE())\n```\n3. Filter the data for specific machines:\n```sql\nAND maintenance_logs.Machine IN ('Machine1', 'Machine2', 'Machine3')\n```\n4. Calculate the total downtime for each machine in each shift:\n```sql\nSUM(maintenance_logs.Downtime_Hours * 60) AS Total_Downtime_in_Minutes\n```\n5. Calculate the total number of shifts for each machine:\n```sql\nCOUNT(DISTINCT production_logs.Date) AS Total_Shifts\n```\n6. Calculate the average downtime per shift for each machine:\n```sql\nTotal_Downtime_in_Minutes / Total_Shifts AS Average_Downtime_per_Shift\n```\n7. Group the results by machine and shift:\n```sql\nGROUP BY maintenance_logs.Machine, production_logs.Date\n```\n8. Join the results with the production logs table to get the shift information:\n```sql\nLEFT JOIN production_logs ON production_logs.Date = maintenance_logs.Date\n```\n9. Calculate the average downtime per shift for each machine:\n```sql\nAVG(Average_Downtime_per_Shift) AS Average_Downtime_per_Shift\n```\n10. Join the results with the quality control and inventory logs tables to get the machine-specific data:\n```sql\nLEFT JOIN quality_control ON quality_control.Date = production_logs.Date\nLEFT JOIN inventory_logs ON inventory_logs.Date = production_logs.Date\n```\n11. Filter the data for the last quarter:\n```sql\nWHERE production_logs.Date >= DATEADD(quarter, -1, GETDATE())\n```\n12. Filter the data for the specific machines:\n```sql\nAND maintenance_logs.Machine IN ('Machine1', 'Machine2', 'Machine3')\n```\n13. Calculate the total downtime for each machine in each shift:\n```sql\nSUM(Average_Downtime_per_Shift) AS Total_Downtime_per_Machine_per_Shift\n```\n14. Calculate the total number of shifts for each machine:\n```sql\nCOUNT(DISTINCT production_logs.Date) AS Total_Shifts_per_Machine\n```\n15. Calculate the average downtime per shift for each machine:\n```sql\nAVG(Total_Downtime_per_Machine_per_Shift) AS Average_Downtime_per_Shift_per_Machine\n```\n16. Join the results with the quality control and inventory logs tables to get the machine-specific data:\n```sql\nLEFT JOIN quality_control ON quality_control.Date = production_logs.Date\nLEFT JOIN inventory_logs ON inventory_logs.Date = production_logs.Date\n```\n17. Filter the data for the last quarter and specific machines:\n```sql\nWHERE production_logs.Date >= DATEADD(quarter, -1, GETDATE())\nAND maintenance_logs.Machine IN ('Machine1', 'Machine2', 'Machine3')\n```\n18. Calculate the total downtime for each machine in each shift:\n```sql\nSUM(Total_Downtime_per_Machine_per_Shift) AS Total_Downtime_per_Machine_per_Shift\n```\n19. Calculate the total number of shifts for each machine:\n```sql\nCOUNT(DISTINCT production_logs.Date) AS Total_Shifts_per_Machine\n```\n20. Calculate the",
    "sql_response": "To find the average downtime per shift for each machine in the last quarter, we need to calculate the total downtime for each machine in each shift and then find the average. We can achieve this by joining the `maintenance_logs`, `production_logs`, and `inventory_logs` tables based on the machine name and shift. We will then group the results by machine and shift, and calculate the total downtime and quantity of machines for each combination. Finally, we'll divide the total downtime by the quantity to get the average downtime per machine.\n\nHere's the SQL query:\n\n```sql\nSELECT m.machine_name, m.shift, AVG(m.downtime_minutes) AS avg_downtime_minutes\nFROM maintenance_logs m\nJOIN production_logs pl ON m.machine_name = pl.machine AND m.shift = pl.shift\nJOIN inventory_logs il ON m.machine_name = il.machine AND m.shift = il.shift\nGROUP BY m.machine_name, m.shift;\n```\n\nThis query joins the `maintenance_logs`, `production_logs`, and `inventory_logs` tables based on the machine name and shift. Then, it groups the results by machine and shift and calculates the average downtime per machine by using the `AVG` function on the `downtime_minutes` column. ",
    "table_selection_response": "{\n  \"tables\": [\n    \"production_logs\"\n  ],\n  \"columns\": [\n    \"Shift\",\n    \"Line_Machine\",\n    \"Actual_Qty\",\n    \"Downtime_Minutes\"\n  ]\n} ",
    "methodology_score": 61.53846153846154,
    "sql_score": 53.76088508208422,
    "table_column_score": 85.0,
    "response_quality_score": 85.81156206130981,
    "overall_score": 67.10900444639891,
    "methodology_details": {
      "method": "keyword_fallback",
      "overlap_count": 8,
      "expected_keyword_count": 13,
      "response_keyword_count": 98
    },
    "sql_details": {
      "table_match": 33.33333333333333,
      "column_match": 33.33333333333333,
      "aggregate_match": 100.0,
      "clause_match": 60.0,
      "fuzzy_score": 53.961456102783735,
      "overall_score": 53.76088508208422,
      "expected_tables": [
        "production_logs"
      ],
      "generated_tables": [
        "maintenance_logs",
        "inventory_logs",
        "production_logs"
      ],
      "expected_columns": [
        "line_machine",
        "pl",
        "downtime_minutes",
        "shift"
      ],
      "generated_columns": [
        "m",
        "downtime_minutes",
        "shift",
        "machine_name"
      ],
      "has_valid_sql": true
    },
    "table_column_details": {
      "overall_score": 85.0,
      "table_score": 100.0,
      "column_score": 75.0,
      "table_precision": 100.0,
      "table_recall": 100.0,
      "column_precision": 75.0,
      "column_recall": 75.0,
      "tables_correct": [
        "production_logs"
      ],
      "tables_missing": [],
      "tables_extra": [],
      "columns_correct": [
        "line_machine",
        "downtime_minutes",
        "shift"
      ],
      "columns_missing": [
        "date"
      ],
      "columns_extra": [
        "actual_qty"
      ],
      "expected_tables": [
        "production_logs"
      ],
      "generated_tables": [
        "production_logs"
      ],
      "expected_columns": [
        "line_machine",
        "date",
        "downtime_minutes",
        "shift"
      ],
      "generated_columns": [
        "line_machine",
        "actual_qty",
        "downtime_minutes",
        "shift"
      ]
    },
    "total_latency_ms": 14188.437938690186,
    "total_tokens": 2880,
    "errors": [],
    "timestamp": "2025-11-30T13:09:45.400066"
  },
  {
    "question_id": "Easy_12",
    "question_text": "How many breakdown maintenance events occurred in the last quarter?",
    "category": "Easy",
    "model_id": "allam-2-7b",
    "methodology_response": "To answer the question about the number of breakdown maintenance events that occurred in the last quarter, we will follow these steps:\n\n1. Connect to the SQL database and select the necessary tables:\n   ```sql\n   SELECT * FROM production_logs\n   JOIN inventory_logs ON production_logs.Material_Code = inventory_logs.Material_Code\n   JOIN maintenance_logs ON production_logs.Machine = maintenance_logs.Machine\n   WHERE production_logs.Date >= DATEADD(QUARTER, DATEDIFF(QUARTER, 0, GETDATE()) - 1, 0)\n   ```\n\n2. Filter the data to only include maintenance events:\n   ```sql\n   WHERE maintenance_logs.Maintenance_Type = 'Breakdown'\n   ```\n\n3. Count the number of rows to find the total number of breakdown maintenance events:\n   ```sql\n   COUNT(*) AS Total_Breakdowns\n   ```\n\n4. Filter the data to only include breakdown maintenance events that occurred during production:\n   ```sql\n   WHERE maintenance_logs.Maintenance_Type = 'Breakdown' AND production_logs.Date = maintenance_logs.Date\n   ```\n\n5. Count the number of rows to find the number of breakdown maintenance events that occurred during production:\n   ```sql\n   COUNT(*) AS Production_Breakdowns\n   ```\n\n6. Calculate the percentage of breakdown maintenance events that occurred during production:\n   ```sql\n   (Production_Breakdowns / Total_Breakdowns) * 100 AS Percentage_Production_Breakdowns\n   ```\n\nThe final SQL query will look like this:\n```sql\nSELECT Total_Breakdowns, Production_Breakdowns, Percentage_Production_Breakdowns\nFROM (\n   SELECT COUNT(*) AS Total_Breakdowns, COUNT(*) AS Production_Breakdowns,\n   (COUNT(*) AS Production_Breakdowns, COUNT(*) AS Total_Breakdowns\n   FROM production_logs\n   JOIN maintenance_logs ON production_logs.Machine = maintenance_logs.Machine AND maintenance_logs.Maintenance_Type = 'Breakdown'\n   JOIN inventory_logs ON production_logs.Machine = inventory_logs.Machine\n   WHERE production_logs.Date >= DATEADD(QUARTER, DATEDIFF(QUARTER, 0, GETDATE()) - 1 AND maintenance_logs.Date = production_logs.Date\n) AS breakdown_events\n```\n\nThis query will give us the total number of breakdown maintenance events and the number of breakdown maintenance events that occurred during production. Then, we can calculate the percentage of breakdown maintenance events that occurred during production by dividing the number of production breakdown events by the total number of breakdown events and multiplying by 100. ",
    "sql_response": "To find the number of breakdown maintenance events that occurred in the last quarter, we need to calculate the total number of breakdown maintenance records for each quarter and then find the count of those records. Since the `maintenance_logs` table has a `Date` column, we can use this to determine the quarters.\n\nHere's the SQL query:\n\n```sql\nSELECT\n    YEAR(Date) AS Year,\n    MONTH(Date) AS Month,\n    COUNT(*) AS Maintenance_Count\nFROM\n    maintenance_logs\nWHERE\n    Maintenance_Type = 'Breakdown'\nGROUP BY\n    YEAR(Date), MONTH(Date)\nHAVING\n    MONTH(Date) >= DATEPART(MONTH, GETDATE()) - 3\nORDER BY\n    YEAR(Date), MONTH(Date);\n```\n\nThis query will return the number of breakdown maintenance events for each month within the last quarter (3 months before the current month). The result will be grouped by year and month, ordered by year and month, and include the year and month in the result column names. ",
    "table_selection_response": "{\n  \"tables\": [\n    \"maintenance_logs\"\n  ],\n  \"columns\": [\n    \"Maintenance_Date\",\n    \"Machine\",\n    \"Breakdown_Date\",\n    \"Downtime_Hours\"\n  ]\n} ",
    "methodology_score": 70.0,
    "sql_score": 66.61486486486487,
    "table_column_score": 60.0,
    "response_quality_score": 89.65676212310791,
    "overall_score": 68.2808789150135,
    "methodology_details": {
      "method": "keyword_fallback",
      "overlap_count": 7,
      "expected_keyword_count": 10,
      "response_keyword_count": 76
    },
    "sql_details": {
      "table_match": 100.0,
      "column_match": 25.0,
      "aggregate_match": 100.0,
      "clause_match": 50.0,
      "fuzzy_score": 52.43243243243243,
      "overall_score": 66.61486486486487,
      "expected_tables": [
        "maintenance_logs"
      ],
      "generated_tables": [
        "maintenance_logs"
      ],
      "expected_columns": [
        "maintenance_type"
      ],
      "generated_columns": [
        "monthdate",
        "yeardate",
        "year",
        "maintenance_type"
      ],
      "has_valid_sql": true
    },
    "table_column_details": {
      "overall_score": 60.0,
      "table_score": 100.0,
      "column_score": 33.33333333333333,
      "table_precision": 100.0,
      "table_recall": 100.0,
      "column_precision": 25.0,
      "column_recall": 50.0,
      "tables_correct": [
        "maintenance_logs"
      ],
      "tables_missing": [],
      "tables_extra": [],
      "columns_correct": [
        "breakdown_date"
      ],
      "columns_missing": [
        "maintenance_type"
      ],
      "columns_extra": [
        "downtime_hours",
        "maintenance_date",
        "machine"
      ],
      "expected_tables": [
        "maintenance_logs"
      ],
      "generated_tables": [
        "maintenance_logs"
      ],
      "expected_columns": [
        "breakdown_date",
        "maintenance_type"
      ],
      "generated_columns": [
        "breakdown_date",
        "downtime_hours",
        "maintenance_date",
        "machine"
      ]
    },
    "total_latency_ms": 10343.23787689209,
    "total_tokens": 2489,
    "errors": [],
    "timestamp": "2025-11-30T13:10:02.199404"
  },
  {
    "question_id": "Complex_7",
    "question_text": "What are the top 3 defect types that lead to rework for Widget-B, and what is their total rework count?",
    "category": "Complex",
    "model_id": "allam-2-7b",
    "methodology_response": "Sure, I can help you with that. Here are the step-by-step calculations to answer the question:\n\n```steps\n1. Connect to the database and select the required tables:\n   - production_logs (for Widget-B rework count)\n   - quality_control (for defect types and rework count)\n   - inventory_logs (for material consumption)\n\n2. Filter production_logs table for Widget-B:\n   - SELECT Production_Logs.*\n     WHERE Production_Logs.Product = 'Widget-B'\n\n3. Filter quality_control table for Widget-B and defect types:\n   - SELECT Quality_Control.*\n     WHERE Quality_Control.Product = 'Widget-B'\n     GROUP BY Quality_Control.Defect_Type\n\n4. Filter inventory_logs table for material consumption:\n   - SELECT Inventory_Logs.*\n     WHERE Inventory_Logs.Material_Code = 'Material_Code_for_Widget-B'\n\n5. Join the filtered production_logs, quality_control, and inventory_logs tables based on common columns:\n   - SELECT Production_Logs.Rework_Count, Quality_Control.Defect_Type\n     FROM Production_Logs\n     JOIN Quality_Control ON Production_Logs.Product = Quality_Control.Product\n     JOIN Inventory_Logs ON Production_Logs.Product = Inventory_Logs.Material_Code\n     WHERE Production_Logs.Product = 'Widget-B'\n\n6. Calculate the total consumption of 'Material_Code_for_Widget-B':\n   - SELECT SUM(Inventory_Logs.Consumption_Kg) AS Total_Consumption_Kg\n     FROM Inventory_Logs\n     WHERE Inventory_Logs.Material_Code = 'Material_Code_for_Widget-B'\n\n7. Calculate the total rework count for each defect type:\n   - SELECT Production_Logs.Rework_Count, Quality_Control.Defect_Type\n     FROM Production_Logs\n     JOIN Quality_Control ON Production_Logs.Product = Quality_Control.Product\n     WHERE Production_Logs.Product = 'Widget-B'\n\n8. Combine the results from steps 6 and 7:\n   - SELECT Production_Logs.Rework_Count, Quality_Control.Defect_Type, Total_Consumption_Kg\n     FROM Production_Logs\n     JOIN Quality_Control ON Production_Logs.Product = Quality_Control.Product\n     JOIN (SELECT SUM(Inventory_Logs.Consumption_Kg) AS Total_Consumption_Kg\n            FROM Inventory_Logs\n            WHERE Inventory_Logs.Material_Code = 'Material_Code_for_Widget-B'\n            GROUP BY Production_Logs.Product) AS Total_Consumption_Kg\n     FROM Production_Logs\n     JOIN Quality_Control ON Production_Logs.Product = Quality_Control.Product\n     JOIN (SELECT SUM(Inventory_Logs.Consumption_Kg) AS Total_Consumption_Kg\n            FROM Inventory_Logs\n            WHERE Inventory_Logs.Material_Code = 'Material_Code_for_Widget-B'\n            GROUP BY Production_Logs.Product) AS Total_Consumption_Kg\n     FROM Production_Logs\n     JOIN Quality_Control ON Production_Logs.Product = Quality_Control.Product\n```\n\n9. Calculate the total rework count for each defect type:\n   - SELECT Production_Logs.Rework_Count, Quality_Control.Defect_Type\n   - JOIN (SELECT SUM(Inventory_Logs.Consumption_Kg)",
    "sql_response": "To find the top 3 defect types that lead to rework for Widget-B and their total rework count, we can use a combination of JOINs and aggregate functions in SQL. Here's the query:\n\n```sql\nSELECT maintenance_logs.Machine, SUM(inventory_logs.Consumption_Kg) AS Total_Consumption, SUM(inventory_logs.Wastage_Kg) AS Total_Wastage, COUNT(quality_control.Defect_Type) AS Total_Rework_Count\nFROM maintenance_logs\nJOIN inventory_logs ON maintenance_logs.Machine = inventory_logs.Material_Code\nJOIN quality_control ON maintenance_logs.Machine = quality_control.Machine\nWHERE inventory_logs.Material_Code = 'Widget-B'\nGROUP BY maintenance_logs.Machine\nORDER BY Total_Rework_Count DESC\nLIMIT 3;\n```\n\nThis query joins the `maintenance_logs`, `inventory_logs`, and `quality_control` tables based on the `Machine` column. We filter the results for `Material_Code` equal to 'Widget-B' and then group the results by `Machine`. Finally, we order the results by the `Total_Rework_Count` column in descending order and limit the result set to the top 3 rows.\n\nThe result will show the top 3 machines with the highest rework count for Widget-B, along with the total consumption and wastage for that machine, and the total number of rework counts for each machine. ",
    "table_selection_response": "{\n  \"tables\": [\n    \"quality_control\",\n    \"production_logs\"\n  ],\n  \"columns\": [\n    \"Product\",\n    \"Failed_Qty\",\n    \"Rework_Count\"\n  ]\n} ",
    "methodology_score": 44.0,
    "sql_score": 54.30411255411254,
    "table_column_score": 66.66666666666666,
    "response_quality_score": 87.51748275756836,
    "overall_score": 57.62485433636289,
    "methodology_details": {
      "method": "keyword_fallback",
      "overlap_count": 11,
      "expected_keyword_count": 25,
      "response_keyword_count": 67
    },
    "sql_details": {
      "table_match": 33.33333333333333,
      "column_match": 25.0,
      "aggregate_match": 100.0,
      "clause_match": 85.71428571428571,
      "fuzzy_score": 45.75757575757575,
      "overall_score": 54.30411255411254,
      "expected_tables": [
        "quality_control"
      ],
      "generated_tables": [
        "maintenance_logs",
        "quality_control",
        "inventory_logs"
      ],
      "expected_columns": [
        "product",
        "defect_type",
        "total_rework_count",
        "rework_count"
      ],
      "generated_columns": [
        "wastage_kg",
        "defect_type",
        "maintenance_logs",
        "consumption_kg",
        "machine",
        "total_rework_count"
      ],
      "has_valid_sql": true
    },
    "table_column_details": {
      "overall_score": 66.66666666666666,
      "table_score": 66.66666666666666,
      "column_score": 66.66666666666666,
      "table_precision": 50.0,
      "table_recall": 100.0,
      "column_precision": 66.66666666666666,
      "column_recall": 66.66666666666666,
      "tables_correct": [
        "quality_control"
      ],
      "tables_missing": [],
      "tables_extra": [
        "production_logs"
      ],
      "columns_correct": [
        "product",
        "rework_count"
      ],
      "columns_missing": [
        "defect_type"
      ],
      "columns_extra": [
        "failed_qty"
      ],
      "expected_tables": [
        "quality_control"
      ],
      "generated_tables": [
        "production_logs",
        "quality_control"
      ],
      "expected_columns": [
        "product",
        "defect_type",
        "rework_count"
      ],
      "generated_columns": [
        "product",
        "rework_count",
        "failed_qty"
      ]
    },
    "total_latency_ms": 12482.51724243164,
    "total_tokens": 2962,
    "errors": [],
    "timestamp": "2025-11-30T13:10:21.387770"
  },
  {
    "question_id": "Medium_21",
    "question_text": "What is the average downtime per shift for Machine-M1 in October 2026?",
    "category": "Medium",
    "model_id": "allam-2-7b",
    "methodology_response": "To answer the question about the average downtime per shift for Machine-M1 in October 2026, we will follow these steps:\n\n1. Connect to the SQL database and select the required tables:\n```sql\nSELECT * FROM production_logs\nINNER JOIN maintenance_logs ON production_logs.Machine = maintenance_logs.Machine\nINNER JOIN inventory_logs ON production_logs.Machine = inventory_logs.Machine\nWHERE production_logs.Date >= '2026-10-01' AND production_logs.Date <= '2026-10-31' AND maintenance_logs.Machine = 'M1'\n```\n2. Filter the data for October 2026 and Machine-M1:\n```sql\nSELECT * FROM result WHERE Date >= '2026-10-01' AND Date <= '2026-10-31' AND Machine = 'M1'\n```\n3. Calculate the total downtime for each shift (morning, afternoon, and night) by summing downtime minutes:\n```sql\nSELECT Shift, SUM(Downtime_Minutes) AS Total_Downtime_Minutes\nFROM result\nGROUP BY Shift;\n```\n4. Calculate the number of shifts for each day:\n```sql\nSELECT DATE(Date) AS Day, COUNT(Shift) AS Shift_Count\nFROM result\nGROUP BY DATE(Date);\n```\n5. Calculate the average downtime per shift by dividing the total downtime minutes by the number of shifts:\n```sql\nSELECT Shift, Total_Downtime_Minutes / Shift_Count AS Average_Downtime_Minutes\nFROM (\n    SELECT Shift, SUM(Downtime_Minutes) AS Total_Downtime_Minutes, COUNT(Shift) AS Shift_Count\n    FROM result\n    GROUP BY Shift, DATE(Date)\n) AS Daily_Downtime;\n```\n6. Calculate the average downtime per shift for Machine-M1 in October 2026:\n```sql\nSELECT AVG(Average_Downtime_Minutes) AS Average_Downtime_M1\nFROM (\n    SELECT Shift, Total_Downtime_Minutes / Shift_Count AS Average_Downtime_Minutes\n    FROM (\n        SELECT Shift, SUM(Downtime_Minutes) AS Total_Downtime_Minutes, COUNT(Shift) AS Shift_Count\n        FROM result\n        GROUP BY Shift, DATE(Date)\n    ) AS Daily_Downtime;\n    WHERE Machine = 'M1';\n```\n7. Calculate the total number of shifts for October 2026:\n```sql\nSELECT COUNT(DISTINCT Shift) AS Total_Shifts_Oct2026\nFROM result\nWHERE Date >= '2026-10-01' AND Date <= '2026-10-31';\n```\n8. Calculate the average downtime per shift for Machine-M1 in October 2026:\n```sql\nSELECT AVG(Average_Downtime_Minutes) AS Average_Downtime_M1\nFROM (\n    SELECT Shift, SUM(Downtime_Minutes) AS Average_Downtime_Minutes\n    FROM (\n        SELECT Shift, SUM(Downtime_Minutes) AS Downtime_Minutes, COUNT(Shift) AS Shift_Count\n        FROM result\n        WHERE Machine = 'M1' AND Date >= '2026-10-01' AND Date <= '2026-10-31'\n    ) AS Daily_Downtime;\n```\n9. Calculate the total number of shifts for October 2026:\n```sql\nSELECT COUNT(DISTINCT Shift) AS Total_Shifts_Oct2026\nFROM result\nWHERE Machine = 'M1' AND Date >= '2026-10-01' AND Date <= '2026-10-31';\n",
    "sql_response": "To find the average downtime per shift for Machine-M1 in October 2026, we can use the following SQL query:\n\n```sql\nSELECT AVG(Downtime_Hours) AS Avg_Downtime_Oct26\nFROM (\n  SELECT Machine, Shift, SUM(Downtime_Hours) AS Downtime_Hours\n  FROM (\n    SELECT Machine, Shift, Machine_Maintenance_Logs.Downtime_Hours, Machine_Maintenance_Logs.Maintenance_Date\n    FROM Machine_Maintenance_Logs\n    WHERE Machine = 'Machine-M1' AND Maintenance_Date >= '2026-10-01' AND Maintenance_Date < '2026-11-01'\n    GROUP BY Machine, Shift, Machine_Maintenance_Logs.Downtime_Hours, Machine_Maintenance_Logs.Maintenance_Date\n  ) AS Maintenance_Logs\n  GROUP BY Machine, Shift\n) AS Downtime_Oct26;\n```\n\nThis query first filters the maintenance logs for Machine-M1 in October 2026, calculates the total downtime for each shift, and then calculates the average downtime per shift. The result will be displayed as \"Avg_Downtime_Oct26\". \n\nPlease note that the date format used in the query is in the format 'YYYY-MM-DD'. If your database uses a different date format, you may need to adjust the query accordingly. ",
    "table_selection_response": "{\n  \"tables\": [\n    \"production_logs\"\n  ],\n  \"columns\": [\n    \"Shift\",\n    \"Downtime_Minutes\"\n  ]\n} ",
    "methodology_score": 64.28571428571429,
    "sql_score": 31.740850642927793,
    "table_column_score": 80.0,
    "response_quality_score": 87.05339765548706,
    "overall_score": 59.10035177628772,
    "methodology_details": {
      "method": "keyword_fallback",
      "overlap_count": 9,
      "expected_keyword_count": 14,
      "response_keyword_count": 77
    },
    "sql_details": {
      "table_match": 0.0,
      "column_match": 20.0,
      "aggregate_match": 33.33333333333333,
      "clause_match": 100.0,
      "fuzzy_score": 33.82789317507419,
      "overall_score": 31.740850642927793,
      "expected_tables": [
        "production_logs"
      ],
      "generated_tables": [
        "maintenance_logs"
      ],
      "expected_columns": [
        "downtime_minutes",
        "shift"
      ],
      "generated_columns": [
        "downtime_hours",
        "maintenance_date",
        "shift",
        "machine"
      ],
      "has_valid_sql": true
    },
    "table_column_details": {
      "overall_score": 80.0,
      "table_score": 100.0,
      "column_score": 66.66666666666666,
      "table_precision": 100.0,
      "table_recall": 100.0,
      "column_precision": 100.0,
      "column_recall": 50.0,
      "tables_correct": [
        "production_logs"
      ],
      "tables_missing": [],
      "tables_extra": [],
      "columns_correct": [
        "downtime_minutes",
        "shift"
      ],
      "columns_missing": [
        "line_machine",
        "date"
      ],
      "columns_extra": [],
      "expected_tables": [
        "production_logs"
      ],
      "generated_tables": [
        "production_logs"
      ],
      "expected_columns": [
        "line_machine",
        "date",
        "downtime_minutes",
        "shift"
      ],
      "generated_columns": [
        "downtime_minutes",
        "shift"
      ]
    },
    "total_latency_ms": 12946.60234451294,
    "total_tokens": 2899,
    "errors": [],
    "timestamp": "2025-11-30T13:10:41.231853"
  },
  {
    "question_id": "Easy_5",
    "question_text": "How many breakdown maintenances were performed on Machine-M2 in Q3 2026?",
    "category": "Easy",
    "model_id": "allam-2-7b",
    "methodology_response": "To answer the question about the number of breakdown maintenances performed on Machine-M2 in Q3 2026, we will follow these steps:\n\n1. Connect to the SQL database and select the necessary tables:\n   ```sql\n   SELECT * FROM inventory_logs;\n   SELECT * FROM maintenance_logs;\n   SELECT * FROM production_logs;\n   ```\n2. Filter the data for the desired period (Q3 2026):\n   ```sql\n   WHERE inventory_logs.Date >= '2026-07-01' AND inventory_logs.Date <= '2026-09-30';\n   WHERE maintenance_logs.Date >= '2026-07-01' AND maintenance_logs.Date <= '2026-09-30';\n   WHERE production_logs.Date >= '2026-07-01' AND production_logs.Date <= '2026-09-30';\n   ```\n3. Filter the data for the specific machine (Machine-M2):\n   ```sql\n   WHERE maintenance_logs.Machine = 'Machine-M2';\n   ```\n4. Filter the data for the specific type of maintenance (Breakdown maintenance):\n   ```sql\n   WHERE maintenance_logs.Maintenance_Type = 'Breakdown';\n   ```\n5. Count the number of filtered records:\n   ```sql\n   COUNT(*) AS Maintenance_Count;\n   ```\n6. Filter the data for the desired period (Q3 2026):\n   ```sql\n   WHERE production_logs.Date >= '2026-07-01' AND production_logs.Date <= '2026-09-30';\n   ```\n7. Filter the data for the specific machine (Machine-M2):\n   ```sql\n   WHERE production_logs.Machine = 'Machine-M2';\n   ```\n8. Filter the data for the specific type of maintenance (Breakdown maintenance):\n   ```sql\n   WHERE production_logs.Maintenance_Type = 'Breakdown';\n   ```\n9. Count the number of filtered records:\n   ```sql\n   COUNT(*) AS Maintenance_Count;\n   ```\n10. Combine the data from steps 7 and 8:\n    ```sql\n    SELECT production_logs.*, maintenance_logs.*\n    FROM production_logs\n    JOIN maintenance_logs ON production_logs.Machine = maintenance_logs.Machine\n    WHERE production_logs.Machine = 'Machine-M2' AND maintenance_logs.Maintenance_Type = 'Breakdown';\n    ```\n11. Combine the data from steps 9 and 10:\n    ```sql\n    SELECT SUM(Maintenance_Count) AS Maintenance_Count\n    FROM (\n        SELECT COUNT(*) AS Maintenance_Count\n        FROM production_logs\n        JOIN maintenance_logs ON production_logs.Machine = maintenance_logs.Machine\n        WHERE production_logs.Machine = 'Machine-M2' AND maintenance_logs.Maintenance_Type = 'Breakdown';\n    ) AS Maintenance_Count;\n    ```\n12. Filter the data for the specific machine (Machine-M2) and maintenance type (Breakdown):\n    ```sql\n    SELECT COUNT(*) AS Maintenance_Count\n    FROM production_logs\n    JOIN maintenance_logs ON production_logs.Machine = maintenance_logs.Machine\n    WHERE production_logs.Machine = 'Machine-M2' AND maintenance_logs.Maintenance_Type = 'Breakdown';\n    ```\n13. Combine the data from steps 12 and 11:\n    ```sql\n    SELECT SUM",
    "sql_response": "To find the number of breakdown maintenances performed on Machine-M2 in Q3 2026, we can use the following SQL query:\n\n```sql\nSELECT COUNT(*)\nFROM maintenance_logs\nWHERE Machine = 'M2' AND Maintenance_Type = 'Breakdown' AND YEAR(Date) = 2026 AND MONTH(Date) BETWEEN 7 AND 9;\n```\n\nThis query selects the count of all rows from the `maintenance_logs` table where the machine is 'M2', the maintenance type is 'Breakdown', the year is 2026, and the month between July and September (inclusive). ",
    "table_selection_response": "{\n  \"tables\": [\n    \"maintenance_logs\"\n  ],\n  \"columns\": [\n    \"Machine\",\n    \"Breakdown_Date\",\n    \"Technician\"\n  ]\n} ",
    "methodology_score": 40.0,
    "sql_score": 95.625,
    "table_column_score": 60.0,
    "response_quality_score": 88.74970602989197,
    "overall_score": 69.3437206029892,
    "methodology_details": {
      "method": "keyword_fallback",
      "overlap_count": 6,
      "expected_keyword_count": 15,
      "response_keyword_count": 72
    },
    "sql_details": {
      "table_match": 100.0,
      "column_match": 100.0,
      "aggregate_match": 100.0,
      "clause_match": 100.0,
      "fuzzy_score": 70.83333333333333,
      "overall_score": 95.625,
      "expected_tables": [
        "maintenance_logs"
      ],
      "generated_tables": [
        "maintenance_logs"
      ],
      "expected_columns": [
        "machine"
      ],
      "generated_columns": [
        "machine"
      ],
      "has_valid_sql": true
    },
    "table_column_details": {
      "overall_score": 60.0,
      "table_score": 100.0,
      "column_score": 33.33333333333333,
      "table_precision": 100.0,
      "table_recall": 100.0,
      "column_precision": 33.33333333333333,
      "column_recall": 33.33333333333333,
      "tables_correct": [
        "maintenance_logs"
      ],
      "tables_missing": [],
      "tables_extra": [],
      "columns_correct": [
        "machine"
      ],
      "columns_missing": [
        "maintenance_date",
        "maintenance_type"
      ],
      "columns_extra": [
        "breakdown_date",
        "technician"
      ],
      "expected_tables": [
        "maintenance_logs"
      ],
      "generated_tables": [
        "maintenance_logs"
      ],
      "expected_columns": [
        "maintenance_date",
        "maintenance_type",
        "machine"
      ],
      "generated_columns": [
        "breakdown_date",
        "technician",
        "machine"
      ]
    },
    "total_latency_ms": 11250.293970108032,
    "total_tokens": 2710,
    "errors": [],
    "timestamp": "2025-11-30T13:10:59.322952"
  },
  {
    "question_id": "Complex_33",
    "question_text": "What are the top 3 most frequently replaced parts across all machines, and what is the total cost associated with replacing these parts?",
    "category": "Complex",
    "model_id": "allam-2-7b",
    "methodology_response": "To answer the question about the top 3 most frequently replaced parts across all machines and the total cost associated with replacing these parts, we will follow these steps:\n\n1. Connect to the database and select the required tables:\n   - Production Logs table (production_logs) to get the breakdown of downtime hours and breakdown dates for each machine.\n   - Maintenance Logs table (maintenance_logs) to get the breakdown of replaced parts and their costs.\n   - Quality Control table (quality_control) to get the breakdown of failed parts and their costs.\n\n2. Filter the data to get the breakdown of downtime hours and breakdown dates for each machine:\n   - Join the production_logs table with the maintenance_logs table on the Machine column to get the breakdown of downtime hours and breakdown dates for each machine.\n   - Join the production_logs table with the quality_control table on the Machine column to get the breakdown of failed parts and their costs for each machine.\n   - Filter the data to get the breakdown for all machines.\n\n3. Calculate the total downtime hours for each machine:\n   - Group the data by Machine and Shift.\n   - Calculate the SUM of Downtime_Hours for each Machine and Shift combination.\n\n4. Filter the data to get the breakdown of breakdown dates and breakdown hours for each machine:\n   - Group the data by Machine, Shift, and Breakdown_Date.\n   - Calculate the SUM of Downtime_Hours for each Machine, Shift, and Breakdown_Date combination.\n\n5. Calculate the total breakdown hours for each machine:\n   - Group the data by Machine and Shift.\n   - Calculate the SUM of Breakdown_Hours for each Machine and Shift combination.\n\n6. Filter the data to get the breakdown of failed parts and their costs for each machine:\n   - Group the data by Machine, Shift, and Breakdown_Date.\n   - Calculate the SUM of Failed_Parts and SUM of Failed_Cost for each Machine, Shift, and Breakdown_Date combination.\n\n7. Calculate the total failed parts and costs for each machine:\n   - Group the data by Machine and Shift.\n   - Calculate the SUM of Failed_Parts and SUM of Failed_Cost for each Machine and Shift combination.\n\n8. Filter the data to get the breakdown of replaced parts and their costs for each machine:\n   - Group the data by Machine, Shift, and Breakdown_Date.\n   - Calculate the SUM of Replaced_Parts and SUM of Replaced_Cost for each Machine, Shift, and Breakdown_Date combination.\n\n9. Calculate the total replaced parts and costs for each machine:\n   - Group the data by Machine and Shift.\n   - Calculate the SUM of Replaced_Parts and SUM of Replaced_Cost for each Machine and Shift combination.\n\n10. Calculate the total breakdown hours, failed parts, and replaced parts for each machine:\n    - Group the data by Machine and Shift.\n    - Calculate the SUM of Breakdown_Hours, SUM of Failed_Parts, and SUM of Replaced_Parts for each Machine and Shift combination.\n\n11. Calculate the total breakdown hours, failed parts, and replaced parts for each machine:\n    - Group the data by Machine and Shift.\n    - Calculate the SUM of Breakdown_Hours, SUM of Failed_Parts, and SUM of Replaced_Parts for each Machine and Shift combination.\n\n12. Calculate the total breakdown hours, failed parts, replaced parts, and costs for each machine:\n    - Group the data by Machine and Shift.\n    - Calculate the SUM of Breakdown_Hours, SUM of Failed_Parts, SUM of Replaced_Parts, and SUM of Failed_Cost + SUM of Replaced_Cost for each Machine and Shift combination.\n\n13. Calculate the total breakdown hours, failed parts, replaced parts, and costs for each machine:\n    - Group the data by Machine and Shift.\n    - Calculate the SUM of Breakdown_Hours, SUM of Failed_Parts, SUM of Replaced_Parts, and SUM of Failed_Cost + SUM of Replaced_Cost for each Machine and Shift combination.\n\n14. Calculate the total breakdown hours, failed parts, replaced parts, and costs for each machine:\n ",
    "sql_response": "To find the top 3 most frequently replaced parts across all machines and the total cost associated with replacing these parts, we can use the following SQL query:\n\n```sql\nSELECT parts.Part_Code, parts.Part_Name, SUM(costs.Cost_Rupees) AS Total_Cost\nFROM maintenance_logs AS maint\nJOIN maintenance_logs AS costs ON maint.Machine = costs.Machine AND maint.Maintenance_Type = 'Repair'\nJOIN inventory_logs AS parts ON maint.Material_Code = parts.Material_Code\nGROUP BY parts.Part_Code, parts.Part_Name\nORDER BY Total_Cost DESC\nLIMIT 3;\n```\n\nThis query joins the `maintenance_logs`, `maintenance_logs` (costs), and `inventory_logs` tables based on the `Machine`, `Maintenance_Type`, and `Material_Code` columns, respectively. We then group the results by `Part_Code` and `Part_Name` and calculate the total cost using the `SUM(costs.Cost_Rupees` column. Finally, we order the results by total cost in descending order and limit the result set to the top 3 rows. \n\nThis query will provide you with the top 3 most frequently replaced parts and their total cost associated with replacing these parts. ",
    "table_selection_response": "{\n  \"tables\": [\n    \"maintenance_logs\"\n  ],\n  \"columns\": [\n    \"Part_Description\",\n    \"Cost_Rupees\"\n  ]\n} ",
    "methodology_score": 50.0,
    "sql_score": 49.604381676625025,
    "table_column_score": 70.0,
    "response_quality_score": 88.28149104118347,
    "overall_score": 58.689682690937104,
    "methodology_details": {
      "method": "keyword_fallback",
      "overlap_count": 11,
      "expected_keyword_count": 22,
      "response_keyword_count": 79
    },
    "sql_details": {
      "table_match": 50.0,
      "column_match": 14.285714285714285,
      "aggregate_match": 66.66666666666666,
      "clause_match": 83.33333333333334,
      "fuzzy_score": 51.330798479087456,
      "overall_score": 49.604381676625025,
      "expected_tables": [
        "maintenance_logs"
      ],
      "generated_tables": [
        "maintenance_logs",
        "inventory_logs"
      ],
      "expected_columns": [
        "cost_rupees",
        "replacementcount",
        "parts_replaced"
      ],
      "generated_columns": [
        "part_name",
        "parts",
        "part_code",
        "cost_rupees",
        "total_cost"
      ],
      "has_valid_sql": true
    },
    "table_column_details": {
      "overall_score": 70.0,
      "table_score": 100.0,
      "column_score": 50.0,
      "table_precision": 100.0,
      "table_recall": 100.0,
      "column_precision": 50.0,
      "column_recall": 50.0,
      "tables_correct": [
        "maintenance_logs"
      ],
      "tables_missing": [],
      "tables_extra": [],
      "columns_correct": [
        "cost_rupees"
      ],
      "columns_missing": [
        "parts_replaced"
      ],
      "columns_extra": [
        "part_description"
      ],
      "expected_tables": [
        "maintenance_logs"
      ],
      "generated_tables": [
        "maintenance_logs"
      ],
      "expected_columns": [
        "cost_rupees",
        "parts_replaced"
      ],
      "generated_columns": [
        "cost_rupees",
        "part_description"
      ]
    },
    "total_latency_ms": 11718.508958816528,
    "total_tokens": 2879,
    "errors": [],
    "timestamp": "2025-11-30T13:11:17.773635"
  },
  {
    "question_id": "Complex_23",
    "question_text": "What is the correlation between Downtime_Minutes and Failed_Qty on a daily basis?",
    "category": "Complex",
    "model_id": "allam-2-7b",
    "methodology_response": "To answer the question about the correlation between Downtime_Minutes and Failed_Qty on a daily basis, we will follow these steps:\n\n1. Connect to the database and select the required tables:\n   ```sql\n   SELECT production_logs.*, quality_control.*, maintenance_logs.*, inventory_logs.*\n   ```\n\n2. Filter the data for daily basis:\n   ```sql\n   WHERE production_logs.Date = 'YYYY-MM-DD'\n   ```\n   Replace 'YYYY-MM-DD' with the desired date for analysis.\n\n3. Calculate the total Downtime_Minutes for each day:\n   ```sql\n   SUM(production_logs.Downtime_Minutes) AS Total_Downtime_Minutes\n   ```\n\n4. Calculate the total Failed_Qty for each day:\n   ```sql\n   SUM(quality_control.Failed_Qty) AS Total_Failed_Qty\n   ```\n\n5. Combine the data from the previous steps:\n   ```sql\n   JOIN production_logs ON production_logs.Date = quality_control.Inspection_Date\n   JOIN quality_control ON production_logs.Date = quality_control.Inspection_Date\n   JOIN maintenance_logs ON production_logs.Date = maintenance_logs.Maintenance_Date\n   JOIN inventory_logs ON production_logs.Date = inventory_logs.Date\n   ```\n\n6. Calculate the correlation between Downtime_Minutes and Failed_Qty:\n   ```sql\n   COUNT(DISTINCT production_logs.Date) AS Days,\n   SUM(production_logs.Downtime_Minutes) AS Downtime_Minutes_Sum,\n   SUM(quality_control.Failed_Qty) AS Failed_Qty_Sum\n   ```\n\n7. Calculate the average Downtime_Minutes and Failed_Qty for each day:\n   ```sql\n   DATEPART(dd, production_logs.Date) AS Days,\n   AVG(production_logs.Downtime_Minutes) AS Downtime_Minutes_Avg,\n   AVG(quality_control.Failed_Qty) AS Failed_Qty_Avg\n   ```\n\n8. Calculate the correlation coefficient between Downtime_Minutes_Avg and Failed_Qty_Avg:\n   ```sql\n   SELECT Days, Downtime_Minutes_Avg, Failed_Qty_Avg,\n          DATEDIFF(day, MIN(production_logs.Date), MAX(production_logs.Date)) AS Days_Range,\n          DATEDIFF(day, MIN(quality_control.Inspection_Date), MAX(quality_control.Inspection_Date)) AS Inspection_Days_Range,\n          DATEDIFF(day, MIN(production_logs.Date), MAX(production_logs.Date)) AS Production_Days_Range,\n          DATEDIFF(day, MIN(quality_control.Inspection_Date), MAX(quality_control.Inspection_Date)) AS Inspection_Days_Range,\n          DATEDIFF(day, MIN(production_logs.Date), MAX(production_logs.Date)) AS Production_Days_Range,\n          DATEDIFF(day, MIN(quality_control.Inspection_Date), MAX(quality_control.Inspection_Date)) AS Inspection_Days_Range,\n          DATEDIFF(day, MIN(production_logs.Date), MAX(production_logs.Date)) AS Production_Days_Range,\n          DATEDIFF(day, MIN(quality_control.Inspection_Date), MAX(quality_control.Inspection_Date)) AS Inspection_Days_Range,\n          DATEDIFF(day, MIN(production_logs.Date), MAX(production_logs.Date))",
    "sql_response": "To find the correlation between Downtime_Minutes and Failed_Qty on a daily basis, we can calculate the average Downtime_Minutes and Failed_Qty for each day and then find the correlation coefficient using the following SQL query:\n\n```sql\nSELECT \n    DATE(Date) AS Date,\n    AVG(Downtime_Minutes) AS Avg_Downtime_Minutes,\n    AVG(Failed_Qty) AS Avg_Failed_Qty,\n    CASE\n        WHEN Avg_Downtime_Minutes IS NULL THEN 'No data available'\n        ELSE ROUND(AVG(Downtime_Minutes) / AVG(Failed_Qty), 2)\n    END AS Correlation_Coefficient\nFROM\n    (\n        SELECT \n            Date,\n            SUM(Downtime_Minutes) AS Downtime_Minutes,\n            SUM(Failed_Qty) AS Failed_Qty\n        FROM production_logs\n        GROUP BY Date, Shift, Line_Machine, Product, Supplier\n    ) AS Production_Logs\nGROUP BY Date, Shift, Line_Machine, Product, Supplier;\n```\n\nThis query first calculates the average Downtime_Minutes and Failed_Qty for each day, shift, line_machine, product, and supplier. Then, it calculates the correlation coefficient between Downtime_Minutes and Failed_Qty using a subquery. The result will show the correlation coefficient for each day, shift, line_machine, product, and supplier. If there is no data available for a particular day, the result will be 'No data available'. ",
    "table_selection_response": "{\n  \"tables\": [\n    \"production_logs\",\n    \"quality_control\"\n  ],\n  \"columns\": [\n    \"Downtime_Minutes\",\n    \"Failed_Qty\"\n  ]\n} ",
    "methodology_score": 68.75,
    "sql_score": 49.295229244114,
    "table_column_score": 80.0,
    "response_quality_score": 86.93016624450684,
    "overall_score": 66.57134685989058,
    "methodology_details": {
      "method": "keyword_fallback",
      "overlap_count": 11,
      "expected_keyword_count": 16,
      "response_keyword_count": 75
    },
    "sql_details": {
      "table_match": 50.0,
      "column_match": 33.33333333333333,
      "aggregate_match": 50.0,
      "clause_match": 75.0,
      "fuzzy_score": 48.07930607187113,
      "overall_score": 49.295229244114,
      "expected_tables": [
        "production_logs",
        "quality_control"
      ],
      "generated_tables": [
        "production_logs"
      ],
      "expected_columns": [
        "pl",
        "corrtotaldowntime",
        "date",
        "downtime_minutes",
        "failed_qty",
        "totalfailures"
      ],
      "generated_columns": [
        "case when avg_downtime_minutes is null then no data available else rounddowntime_minutes / failed_qty",
        "datedate",
        "date",
        "downtime_minutes",
        "failed_qty",
        "2 end"
      ],
      "has_valid_sql": true
    },
    "table_column_details": {
      "overall_score": 80.0,
      "table_score": 100.0,
      "column_score": 66.66666666666666,
      "table_precision": 100.0,
      "table_recall": 100.0,
      "column_precision": 100.0,
      "column_recall": 50.0,
      "tables_correct": [
        "production_logs",
        "quality_control"
      ],
      "tables_missing": [],
      "tables_extra": [],
      "columns_correct": [
        "downtime_minutes",
        "failed_qty"
      ],
      "columns_missing": [
        "inspection_date",
        "date"
      ],
      "columns_extra": [],
      "expected_tables": [
        "production_logs",
        "quality_control"
      ],
      "generated_tables": [
        "production_logs",
        "quality_control"
      ],
      "expected_columns": [
        "inspection_date",
        "date",
        "downtime_minutes",
        "failed_qty"
      ],
      "generated_columns": [
        "downtime_minutes",
        "failed_qty"
      ]
    },
    "total_latency_ms": 13069.833755493164,
    "total_tokens": 3005,
    "errors": [],
    "timestamp": "2025-11-30T13:11:37.751740"
  },
  {
    "question_id": "Easy_28",
    "question_text": "What is the total cost of parts replaced for Machine-M3?",
    "category": "Easy",
    "model_id": "allam-2-7b",
    "methodology_response": "To find the total cost of parts replaced for Machine-M3, we will follow these steps:\n\n1. Connect to the database and select the necessary tables:\n```sql\nSELECT * FROM production_logs\nINNER JOIN maintenance_logs ON production_logs.Machine = maintenance_logs.Machine\nWHERE maintenance_logs.Machine = 'M3';\n```\n2. Filter the data to only include Machine-M3:\n```sql\nSELECT SUM(cost_rupees) AS Total_Cost_M3\nFROM (\n    SELECT maintenance_logs.cost_rupees AS cost_rupees\n    FROM production_logs\n    INNER JOIN maintenance_logs ON production_logs.Machine = maintenance_logs.Machine\n    WHERE maintenance_logs.Machine = 'M3'\n) AS Maintenance_Cost;\n```\n3. Calculate the total cost of parts replaced for Machine-M3:\n```sql\nSELECT SUM(cost_rupees) AS Total_Cost_M3\nFROM (\n    SELECT maintenance_logs.cost_rupees AS cost_rupees\n    FROM production_logs\n    INNER JOIN maintenance_logs ON production_logs.Machine = maintenance_logs.Machine\n    WHERE maintenance_logs.Machine = 'M3'\n) AS Maintenance_Cost;\n```\nIn this case, we are directly calculating the total cost of parts replaced for Machine-M3 from the maintenance logs table. However, if we needed to consider additional factors, such as the number of parts replaced or the total downtime, we would need to include additional tables and calculations. ",
    "sql_response": "To find the total cost of parts replaced for Machine-M3, we can join the `inventory_logs` table with the `maintenance_logs` table on the `Machine` column. Then, we can filter for Machine-M3 and calculate the total cost using the `SUM` function on the `Cost_Rupees` column. Here's the SQL query:\n\n```sql\nSELECT SUM(inventory_logs.Cost_Rupees) AS Total_Cost\nFROM inventory_logs\nJOIN maintenance_logs ON inventory_logs.Machine = maintenance_logs.Machine\nWHERE maintenance_logs.Machine = 'M3';\n```\n\nThis query will return the total cost of parts replaced for Machine-M3. ",
    "table_selection_response": "{\n  \"tables\": [\n    \"maintenance_logs\"\n  ],\n  \"columns\": [\n    \"Machine\",\n    \"Parts_Replaced\",\n    \"Cost_Rupees\"\n  ]\n} ",
    "methodology_score": 42.857142857142854,
    "sql_score": 54.3359375,
    "table_column_score": 88.0,
    "response_quality_score": 89.6418879032135,
    "overall_score": 62.838909772464206,
    "methodology_details": {
      "method": "keyword_fallback",
      "overlap_count": 3,
      "expected_keyword_count": 7,
      "response_keyword_count": 55
    },
    "sql_details": {
      "table_match": 50.0,
      "column_match": 50.0,
      "aggregate_match": 50.0,
      "clause_match": 75.0,
      "fuzzy_score": 53.90625,
      "overall_score": 54.3359375,
      "expected_tables": [
        "maintenance_logs"
      ],
      "generated_tables": [
        "maintenance_logs",
        "inventory_logs"
      ],
      "expected_columns": [
        "cost_rupees",
        "machine"
      ],
      "generated_columns": [
        "cost_rupees"
      ],
      "has_valid_sql": true
    },
    "table_column_details": {
      "overall_score": 88.0,
      "table_score": 100.0,
      "column_score": 80.0,
      "table_precision": 100.0,
      "table_recall": 100.0,
      "column_precision": 66.66666666666666,
      "column_recall": 100.0,
      "tables_correct": [
        "maintenance_logs"
      ],
      "tables_missing": [],
      "tables_extra": [],
      "columns_correct": [
        "cost_rupees",
        "machine"
      ],
      "columns_missing": [],
      "columns_extra": [
        "parts_replaced"
      ],
      "expected_tables": [
        "maintenance_logs"
      ],
      "generated_tables": [
        "maintenance_logs"
      ],
      "expected_columns": [
        "cost_rupees",
        "machine"
      ],
      "generated_columns": [
        "cost_rupees",
        "parts_replaced",
        "machine"
      ]
    },
    "total_latency_ms": 10358.112096786499,
    "total_tokens": 2110,
    "errors": [],
    "timestamp": "2025-11-30T13:11:54.452561"
  },
  {
    "question_id": "Easy_30",
    "question_text": "How much total waste was recorded in 2025?",
    "category": "Easy",
    "model_id": "allam-2-7b",
    "methodology_response": "To answer the question about the total waste recorded in 2025, we will follow these steps:\n\n1. Connect to the database and select the required tables:\n   ```sql\n   SELECT * FROM inventory_logs\n   JOIN production_logs ON inventory_logs.Date = production_logs.Date\n   JOIN quality_control ON production_logs.Date = quality_control.Inspection_Date\n   JOIN maintenance_logs ON production_logs.Date = maintenance_logs.Maintenance_Date\n   WHERE production_logs.Date >= '2025-01-01' AND production_logs.Date <= '2025-12-31';\n   ```\n\n2. Calculate the waste quantity:\n   ```sql\n   SELECT SUM(CASE WHEN quality_control.Defect_Type = 'Waste' THEN quality_control.Wastage_Kg ELSE 0 END) AS Total_Waste_Kg\n   FROM inventory_logs\n   JOIN production_logs ON inventory_logs.Date = production_logs.Date\n   JOIN quality_control ON production_logs.Date = quality_control.Inspection_Date\n   JOIN maintenance_logs ON production_logs.Date = maintenance_logs.Maintenance_Date;\n   ```\n\n3. Calculate the waste cost:\n   ```sql\n   SELECT SUM(quality_control.Wastage_Kg * inventory_logs.Unit_Cost_Rupees) AS Total_Waste_Cost\n   FROM inventory_logs\n   JOIN production_logs ON inventory_logs.Date = production_logs.Date\n   JOIN quality_control ON production_logs.Date = quality_control.Inspection_Date\n   JOIN maintenance_logs ON production_logs.Date = maintenance_logs.Maintenance_Date;\n   ```\n\n4. Calculate the waste rate:\n   ```sql\n   SELECT SUM(quality_control.Wastage_Kg) / SUM(inventory_logs.Consumption_Kg) AS Waste_Rate\n   FROM inventory_logs\n   JOIN production_logs ON inventory_logs.Date = production_logs.Date\n   JOIN quality_control ON production_logs.Date = quality_control.Inspection_Date\n   JOIN maintenance_logs ON production_logs.Date = maintenance_logs.Maintenance_Date;\n   ```\n\n5. Calculate the waste rate per unit of production:\n   ```sql\n   SELECT SUM(quality_control.Wastage_Kg) / SUM(production_logs.Consumption_Kg) AS Waste_Rate_Per_Unit\n   FROM inventory_logs\n   JOIN production_logs ON inventory_logs.Date = production_logs.Date\n   JOIN quality_control ON production_logs.Date = quality_control.Inspection_Date\n   JOIN maintenance_logs ON production_logs.Date = maintenance_logs.Maintenance_Date;\n   ```\n\n6. Calculate the total production quantity:\n   ```sql\n   SELECT SUM(production_logs.Consumption_Kg) AS Total_Production_Quantity\n   FROM inventory_logs\n   JOIN production_logs ON inventory_logs.Date = production_logs.Date;\n   ```\n\n7. Calculate the total production cost:\n   ```sql\n   SELECT SUM(production_logs.Consumption_Kg * inventory_logs.Unit_Cost_Rupees) AS Total_Production_Cost\n   FROM inventory_logs\n   JOIN production_logs ON inventory_logs.Date = production_logs.Date;\n   ```\n\n8. Calculate the total production rate:\n   ```sql\n   SELECT SUM(production_logs.Consumption_Kg) AS Total_Production_Rate\n   FROM inventory_logs\n   JOIN production_logs ON inventory_logs.Date = production_logs.Date;\n   ```\n\n9. Calculate the total production rate per unit:\n   ```sql",
    "sql_response": "To find the total waste recorded in the year 2025, we can join the `inventory_logs` table with the `production_logs` table based on the `Material_Code` column. We can then filter the results for the year 2025 and calculate the total waste by summing the `Wastage_Kg` column. Finally, we can join the `quality_control` table to get the defect type and supplier information.\n\nHere's the SQL query:\n\n```sql\nSELECT\n    il.Material_Code,\n    il.Wastage_Kg AS Total_Wastage_Kg,\n    qc.Defect_Type,\n    qc.Supplier\nFROM\n    inventory_logs il\n    INNER JOIN production_logs pl ON il.Material_Code = pl.Material_Code\n    INNER JOIN quality_control qc ON il.Material_Code = qc.Material_Code\nWHERE\n    il.Date >= '2025-01-01' AND il.Date <= '2025-12-31'\nGROUP BY\n    il.Material_Code, qc.Defect_Type, qc.Supplier\nORDER BY\n    il.Material_Code;\n```\n\nThis query joins the `inventory_logs`, `production_logs`, and `quality_control` tables based on the `Material_Code` column. We filter the results for the year 2025 using the `il.Date` column and group the results by `il.Material_Code`, `qc.Defect_Type`, and `qc.Supplier`. Finally, we order the results by `il.Material_Code`. ",
    "table_selection_response": "{\n  \"tables\": [\n    \"inventory_logs\"\n  ],\n  \"columns\": [\n    \"Wastage_Kg\"\n  ]\n} ",
    "methodology_score": 14.285714285714285,
    "sql_score": 24.857446163178643,
    "table_column_score": 80.0,
    "response_quality_score": 88.14502024650574,
    "overall_score": 41.80032246747738,
    "methodology_details": {
      "method": "keyword_fallback",
      "overlap_count": 1,
      "expected_keyword_count": 7,
      "response_keyword_count": 62
    },
    "sql_details": {
      "table_match": 33.33333333333333,
      "column_match": 20.0,
      "aggregate_match": 0.0,
      "clause_match": 42.857142857142854,
      "fuzzy_score": 33.970276008492576,
      "overall_score": 24.857446163178643,
      "expected_tables": [
        "inventory_logs"
      ],
      "generated_tables": [
        "production_logs",
        "quality_control",
        "inventory_logs"
      ],
      "expected_columns": [
        "wastage_kg"
      ],
      "generated_columns": [
        "material_code",
        "wastage_kg",
        "il",
        "defect_type",
        "supplier"
      ],
      "has_valid_sql": true
    },
    "table_column_details": {
      "overall_score": 80.0,
      "table_score": 100.0,
      "column_score": 66.66666666666666,
      "table_precision": 100.0,
      "table_recall": 100.0,
      "column_precision": 100.0,
      "column_recall": 50.0,
      "tables_correct": [
        "inventory_logs"
      ],
      "tables_missing": [],
      "tables_extra": [],
      "columns_correct": [
        "wastage_kg"
      ],
      "columns_missing": [
        "date"
      ],
      "columns_extra": [],
      "expected_tables": [
        "inventory_logs"
      ],
      "generated_tables": [
        "inventory_logs"
      ],
      "expected_columns": [
        "wastage_kg",
        "date"
      ],
      "generated_columns": [
        "wastage_kg"
      ]
    },
    "total_latency_ms": 11854.979753494263,
    "total_tokens": 2935,
    "errors": [],
    "timestamp": "2025-11-30T13:12:12.743703"
  },
  {
    "question_id": "Medium_31",
    "question_text": "What is the average downtime (in minutes) per shift for Machine-M1 on Line-1 during the last quarter?",
    "category": "Medium",
    "model_id": "allam-2-7b",
    "methodology_response": "To answer the question about the average downtime per shift for Machine-M1 on Line-1 during the last quarter, we will follow these steps:\n\n1. Connect to the SQL database and select the required tables:\n   ```sql\n   SELECT production_logs, maintenance_logs, inventory_logs\n   ```\n\n2. Filter the data for the last quarter (let's assume it starts from January 1st):\n   ```sql\n   WHERE production_logs.Date >= DATEADD(quarter, DATEDIFF(quarter, 0, GETDATE()) - 1, 0)\n   ```\n\n3. Filter for Line-1 and Machine-M1:\n   ```sql\n   AND production_logs.Line_Machine = 'Line-1 Machine-M1'\n   ```\n\n4. Filter for the last quarter:\n   ```sql\n   AND maintenance_logs.Maintenance_Date >= DATEADD(quarter, DATEDIFF(quarter, 0, GETDATE()) - 1, 0)\n   ```\n\n5. Filter for the required columns:\n   ```sql\n   SELECT production_logs.Date, production_logs.Shift, production_logs.Line_Machine, SUM(maintenance_logs.Downtime_Hours) AS Downtime_Hours, SUM(inventory_logs.Consumption_Kg) AS Consumption_Kg\n   FROM production_logs\n   JOIN maintenance_logs ON production_logs.Date = maintenance_logs.Date AND production_logs.Line_Machine = maintenance_logs.Line_Machine\n   JOIN inventory_logs ON production_logs.Date = inventory_logs.Date AND production_logs.Line_Machine = inventory_logs.Line_Machine\n   WHERE production_logs.Line_Machine = 'Line-1 Machine-M1' AND maintenance_logs.Maintenance_Date >= DATEADD(quarter, DATEDIFF(quarter, 0, GETDATE()) - 1, 0) AND maintenance_logs.Maintenance_Date <= DATEADD(quarter, DATEDIFF(quarter, 0, GETDATE()) - 1, 0)\n   ```\n\n6. Calculate the downtime in minutes:\n   ```sql\n   AND CONVERT(VARCHAR(10), maintenance_logs.Maintenance_Date, 103) = CONVERT(VARCHAR(10), GETDATE(), 103)\n   ```\n\n7. Calculate the consumption in kilograms:\n   ```sql\n   AND CONVERT(VARCHAR(10), production_logs.Date, 103) = CONVERT(VARCHAR(10), GETDATE(), 103)\n   ```\n\n8. Calculate the average downtime per shift:\n   ```sql\n   GROUP BY production_logs.Date, production_logs.Shift\n   ```\n\n9. Calculate the average consumption per shift:\n   ```sql\n   GROUP BY production_logs.Date, production_logs.Shift\n   ```\n\n10. Calculate the average downtime per shift and consumption per shift:\n    ```sql\n    SELECT AVG(Downtime_Hours*24) AS Downtime_Minutes, AVG(Consumption_Kg) AS Consumption_Kg\n    FROM (\n        SELECT production_logs.Date, production_logs.Shift, SUM(maintenance_logs.Downtime_Hours*24) AS Downtime_Minutes, SUM(inventory_logs.Consumption_Kg) AS Consumption_Kg\n        FROM production_logs\n        JOIN maintenance_logs ON production_logs.Date = maintenance_logs.Maintenance_Date\n        JOIN inventory_logs ON production_logs.Date = inventory_logs.Date\n        WHERE production_logs.Line_Machine = 'Line-1 Machine-M1'\n        GROUP BY production",
    "sql_response": "To find the average downtime per shift for Machine-M1 on Line-1 during the last quarter, we can use the following SQL query:\n\n```sql\nSELECT AVG(Downtime_Minutes) AS Avg_Downtime_Minutes\nFROM (\n  SELECT Machine, Shift, MIN(Maintenance_Date) AS Maintenance_Date, SUM(Downtime_Hours * 60) AS Downtime_Minutes\n  FROM (\n    SELECT Machine, Shift, Maintenance_Date, Downtime_Hours, Issue_Description, Technician\n    FROM maintenance_logs\n    WHERE Machine = 'Machine-M1' AND Line = 'Line-1' AND Maintenance_Date >= DATEADD(QUARTER, DATEDIFF(QUARTER, 0, GETDATE()) - 1, 0) AND Maintenance_Date <= DATEADD(QUARTER, DATEDIFF(QUARTER, 0, GETDATE()), 0)\n  ) AS Maintenance_Logs\n  GROUP BY Machine, Shift, Maintenance_Date, Downtime_Hours, Issue_Description, Technician\n) AS Maintenance_Data\nGROUP BY Machine, Shift;\n```\n\nThis query first filters the maintenance logs for Machine-M1 on Line-1 for the last quarter using the `DATEDIFF` function to calculate the number of quarters since January 1, 2000, and the `GETDATE()` function to get the current date. Then, it groups the data by Machine, Shift, Maintenance_Date, Downtime_Hours, Issue_Description, and Technician.\n\nNext, it calculates the downtime in minutes by multiplying Downtime_Hours by 60 and groups the data by Machine, Shift, Downtime_Hours, Issue_Description, and Technician. Finally, it calculates the average downtime per shift by grouping the data by Machine and Shift.\n\nPlease note that this query assumes the `maintenance_logs` table has the necessary columns for Machine, Shift, Maintenance_Date, Downtime_Hours, Issue_Description, and Technician. If these columns are not present, please provide the correct column names in the query. \n\nIf you have a different table name for the maintenance logs, please replace \"maintenance_logs\" with the actual table name in the query. ",
    "table_selection_response": "{\n  \"tables\": [\n    \"production_logs\"\n  ],\n  \"columns\": [\n    \"Shift\",\n    \"Line_Machine\",\n    \"Machine\",\n    \"Downtime_Minutes\"\n  ]\n} ",
    "methodology_score": 46.666666666666664,
    "sql_score": 39.154649086663916,
    "table_column_score": 85.0,
    "response_quality_score": 88.12971806526184,
    "overall_score": 57.76709898685856,
    "methodology_details": {
      "method": "keyword_fallback",
      "overlap_count": 7,
      "expected_keyword_count": 15,
      "response_keyword_count": 77
    },
    "sql_details": {
      "table_match": 0.0,
      "column_match": 22.22222222222222,
      "aggregate_match": 66.66666666666666,
      "clause_match": 100.0,
      "fuzzy_score": 35.10506798516687,
      "overall_score": 39.154649086663916,
      "expected_tables": [
        "production_logs"
      ],
      "generated_tables": [
        "maintenance_logs"
      ],
      "expected_columns": [
        "line_machine",
        "downtime_minutes",
        "shift"
      ],
      "generated_columns": [
        "maintenance_date",
        "downtime_minutes",
        "technician",
        "issue_description",
        "downtime_hours * 60",
        "machine",
        "downtime_hours",
        "shift"
      ],
      "has_valid_sql": true
    },
    "table_column_details": {
      "overall_score": 85.0,
      "table_score": 100.0,
      "column_score": 75.0,
      "table_precision": 100.0,
      "table_recall": 100.0,
      "column_precision": 75.0,
      "column_recall": 75.0,
      "tables_correct": [
        "production_logs"
      ],
      "tables_missing": [],
      "tables_extra": [],
      "columns_correct": [
        "line_machine",
        "downtime_minutes",
        "shift"
      ],
      "columns_missing": [
        "date"
      ],
      "columns_extra": [
        "machine"
      ],
      "expected_tables": [
        "production_logs"
      ],
      "generated_tables": [
        "production_logs"
      ],
      "expected_columns": [
        "line_machine",
        "date",
        "downtime_minutes",
        "shift"
      ],
      "generated_columns": [
        "line_machine",
        "downtime_minutes",
        "shift",
        "machine"
      ]
    },
    "total_latency_ms": 11870.28193473816,
    "total_tokens": 3118,
    "errors": [],
    "timestamp": "2025-11-30T13:12:31.076846"
  },
  {
    "question_id": "Complex_9",
    "question_text": "Which supplier provides the material with the lowest unit cost, considering only materials consumed after 2026-01-01?",
    "category": "Complex",
    "model_id": "allam-2-7b",
    "methodology_response": "To answer the question, we will follow these steps:\n\n1. Connect to the database and select the required tables:\n   - Production logs (production_logs) to get the consumption details\n   - Quality control (quality_control) to get the supplier information\n   - Maintenance logs (maintenance_logs) to get the breakdown details\n   - Inventory logs (inventory_logs) to get the supplier information\n\n2. Filter the data for the desired date range:\n   - Select the rows where the date is after January 1, 2026:\n     ```sql\n     SELECT *\n     FROM production_logs\n     WHERE Date > '2026-01-01'\n     ```\n\n3. Filter the data for the materials consumed after the desired date:\n   - Join the filtered production logs table with the inventory logs table on the material code:\n     ```sql\n     SELECT pl.Material_Code, il.Supplier\n     FROM production_logs pl\n     JOIN inventory_logs il ON pl.Material_Code = il.Material_Code\n     WHERE pl.Date > '2026-01-01'\n     ```\n\n4. Filter the data for the suppliers:\n   - Join the filtered production logs table with the quality control table on the material code:\n     ```sql\n     SELECT pl.Material_Code, il.Supplier, qc.Supplier_Name\n     FROM production_logs pl\n     JOIN inventory_logs il ON pl.Material_Code = il.Material_Code\n     JOIN quality_control qc ON pl.Material_Code = qc.Material_Code\n     WHERE pl.Date > '2026-01-01'\n     ```\n\n5. Filter the data for the suppliers and their suppliers' names:\n   - Join the filtered production logs table with the maintenance logs table on the material code:\n     ```sql\n     SELECT pl.Material_Code, il.Supplier, qc.Supplier_Name, ml.Supplier_Name\n     FROM production_logs pl\n     JOIN inventory_logs il ON pl.Material_Code = il.Material_Code\n     JOIN quality_control qc ON pl.Material_Code = qc.Material_Code\n     JOIN maintenance_logs ml ON pl.Material_Code = ml.Material_Code\n     WHERE pl.Date > '2026-01-01'\n     ```\n\n6. Calculate the total cost for each supplier:\n   - Calculate the total consumption for each supplier:\n     ```sql\n     SELECT il.Supplier, SUM(pl.Quantity) AS Total_Consumption\n     FROM production_logs pl\n     JOIN inventory_logs il ON pl.Material_Code = il.Material_Code\n     GROUP BY il.Supplier\n     ```\n\n7. Calculate the total cost for each supplier:\n   - Calculate the total consumption cost for each supplier:\n     ```sql\n     SELECT il.Supplier, SUM(pl.Quantity * il.Unit_Cost) AS Total_Consumption_Cost\n     FROM production_logs pl\n     JOIN inventory_logs il ON pl.Material_Code = il.Material_Code\n     GROUP BY il.Supplier\n     ```\n\n8. Calculate the total cost for each supplier and their suppliers:\n   - Calculate the total consumption cost for each supplier and their suppliers:\n     ```sql\n     SELECT il.Supplier, il.Supplier_Supplier, SUM(pl.Quantity * il.Unit_Cost) AS Total_Consumption_Cost\n     FROM production_logs pl\n     JOIN inventory_logs il ON pl.Material_Code = il.Material_Code\n     JOIN maintenance_logs",
    "sql_response": "To find the supplier with the lowest unit cost, we need to calculate the total cost for each supplier and then find the supplier with the minimum cost. We will also filter the data for materials consumed after 2026-01-01. Here's the SQL query:\n\n```sql\nSELECT s.Supplier, SUM(il.Consumption_Kg * i.Unit_Cost_Rupees) AS Total_Cost\nFROM inventory_logs il\nJOIN inventory i ON il.Material_Code = i.Material_Code\nJOIN suppliers s ON i.Supplier = s.Supplier_Name\nWHERE il.Date > '2026-01-01'\nGROUP BY s.Supplier;\n```\n\nThis query joins the `inventory_logs`, `inventory`, and `suppliers` tables. We filter the data for materials consumed after January 1, 2026, and then calculate the total cost for each supplier by multiplying the consumption quantity (`Consumption_Kg`) with the unit cost (`Unit_Cost_Rupees`) and grouping by the supplier. The result will show the suppliers and their total cost. ",
    "table_selection_response": "{\n  \"tables\": [\n    \"inventory_logs\",\n    \"production_logs\"\n  ],\n  \"columns\": [\n    \"Supplier\",\n    \"Unit_Cost_Rupees\",\n    \"Product\",\n    \"Actual_Qty\",\n    \"Material_Code\",\n    \"Material_Name\",\n    \"Opening_Stock_Kg\",\n    \"Consumption_Kg\",\n    \"Received_Kg\",\n    \"Closing_Stock_Kg\",\n    \"Wastage_Kg\"\n  ]\n} ",
    "methodology_score": 52.63157894736842,
    "sql_score": 49.75853548966756,
    "table_column_score": 50.66666666666666,
    "response_quality_score": 86.11104416847229,
    "overall_score": 54.48273218910806,
    "methodology_details": {
      "method": "keyword_fallback",
      "overlap_count": 10,
      "expected_keyword_count": 19,
      "response_keyword_count": 79
    },
    "sql_details": {
      "table_match": 100.0,
      "column_match": 33.33333333333333,
      "aggregate_match": 0.0,
      "clause_match": 57.14285714285714,
      "fuzzy_score": 52.358490566037744,
      "overall_score": 49.75853548966756,
      "expected_tables": [
        "inventory_logs"
      ],
      "generated_tables": [
        "inventory_logs"
      ],
      "expected_columns": [
        "material_name",
        "min",
        "date",
        "unit_cost_rupees",
        "supplier"
      ],
      "generated_columns": [
        "s",
        "unit_cost_rupees",
        "supplier"
      ],
      "has_valid_sql": true
    },
    "table_column_details": {
      "overall_score": 50.66666666666666,
      "table_score": 66.66666666666666,
      "column_score": 40.0,
      "table_precision": 50.0,
      "table_recall": 100.0,
      "column_precision": 27.27272727272727,
      "column_recall": 75.0,
      "tables_correct": [
        "inventory_logs"
      ],
      "tables_missing": [],
      "tables_extra": [
        "production_logs"
      ],
      "columns_correct": [
        "material_name",
        "supplier",
        "unit_cost_rupees"
      ],
      "columns_missing": [
        "date"
      ],
      "columns_extra": [
        "material_code",
        "wastage_kg",
        "closing_stock_kg",
        "product",
        "opening_stock_kg",
        "consumption_kg",
        "received_kg",
        "actual_qty"
      ],
      "expected_tables": [
        "inventory_logs"
      ],
      "generated_tables": [
        "inventory_logs",
        "production_logs"
      ],
      "expected_columns": [
        "material_name",
        "supplier",
        "date",
        "unit_cost_rupees"
      ],
      "generated_columns": [
        "material_code",
        "wastage_kg",
        "material_name",
        "closing_stock_kg",
        "product",
        "opening_stock_kg",
        "unit_cost_rupees",
        "consumption_kg",
        "received_kg",
        "actual_qty",
        "supplier"
      ]
    },
    "total_latency_ms": 13888.95583152771,
    "total_tokens": 2957,
    "errors": [],
    "timestamp": "2025-11-30T13:12:51.872593"
  },
  {
    "question_id": "Complex_19",
    "question_text": "How does the 'Downtime_Minutes' in production relate to the 'Downtime_Hours' in maintenance logs when the 'Issue_Description' involves 'Motor overheating and failure to start'?",
    "category": "Complex",
    "model_id": "allam-2-7b",
    "methodology_response": "To answer the question about the relationship between 'Downtime_Minutes' in production and 'Downtime_Hours' in maintenance logs when the 'Issue_Description' involves 'Motor overheating and failure to start', we can follow these steps:\n\n1. Connect to the database and select the necessary tables:\n   - production_logs (for Downtime_Minutes)\n   - maintenance_logs (for Downtime_Hours, Issue_Description)\n\n2. Filter the data based on the Issue_Description:\n   - Maintenance_Logs: Issue_Description = 'Motor overheating and failure to start'\n   - Production_Logs: Date = maintenance_logs.Maintenance_Date\n\n3. Calculate the total downtime in minutes for the selected production logs:\n   - Production_Logs: Sum(Downtime_Minutes)\n\n4. Filter the maintenance logs to find the corresponding maintenance events for the selected production events:\n   - Maintenance_Logs: Production_Logs.Date = Maintenance_Logs.Maintenance_Date\n\n5. Calculate the total downtime in hours for the selected maintenance events:\n   - Maintenance_Logs: Sum(Downtime_Hours)\n\n6. Calculate the conversion factor between downtime in minutes and hours:\n   - Calculate the ratio of downtime in hours to downtime in minutes for the selected maintenance events:\n     - Maintenance_Logs: Sum(Downtime_Hours) / Sum(Downtime_Minutes)\n\n7. Join the calculated conversion factor with the production logs to convert downtime in minutes to hours:\n   - Production_Logs: Join(Maintenance_Logs, Production_Logs.Date = Maintenance_Logs.Maintenance_Date)\n   - Production_Logs: Downtime_Hours = Downtime_Minutes * Conversion_Factor\n\n8. Calculate the correlation between downtime in hours and downtime in minutes:\n   - Production_Logs: Correlation(Downtime_Hours, Downtime_Minutes)\n\n9. Filter the production logs to find the correlation for the selected maintenance events:\n   - Production_Logs: Maintenance_Logs.Date = Maintenance_Logs.Maintenance_Date\n\n10. Calculate the total downtime in hours for the selected maintenance events:\n    - Maintenance_Logs: Sum(Downtime_Hours)\n\n11. Filter the maintenance logs to find the correlation for the selected maintenance events:\n    - Maintenance_Logs: Maintenance_Logs.Date = Maintenance_Logs.Maintenance_Date\n\n12. Calculate the correlation between downtime in hours and downtime in minutes for the selected maintenance events:\n    - Maintenance_Logs: Correlation(Downtime_Hours, Downtime_Minutes)\n\n13. Calculate the correlation between downtime in hours and downtime in minutes for the selected maintenance events:\n    - Maintenance_Logs: Correlation(Downtime_Hours, Downtime_Minutes)\n\n14. Filter the maintenance logs to find the correlation for the selected maintenance events:\n    - Maintenance_Logs: Maintenance_Logs.Date = Maintenance_Logs.Maintenance_Date\n\n15. Calculate the correlation between downtime in hours and downtime in minutes for the selected maintenance events:\n    - Maintenance_Logs: Correlation(Downtime_Hours, Downtime_Minutes)\n\n16. Filter the maintenance logs to find the correlation for the selected maintenance events:\n    - Maintenance_Logs: Maintenance_Logs.Date = Maintenance_Logs.Maintenance_Date\n\n17. Calculate the correlation between downtime in hours and downtime in minutes for the selected maintenance events:\n    - Maintenance_Logs: Correlation(Downtime_Hours, Downtime_Minutes)\n\n18. Filter the maintenance logs to find the correlation for the selected maintenance events:\n    - Maintenance_Logs: Maintenance_Logs.Date = Maintenance_Logs.Maintenance_Date\n\n19. Calculate the correlation between downtime in hours and downtime in minutes for the selected maintenance events:\n    - Maintenance_Logs: Correlation(Downtime_Hours, Downtime_Minutes)\n\n20. Filter the maintenance logs to",
    "sql_response": "To find the relationship between the 'Downtime_Minutes' in production and the 'Downtime_Hours' in maintenance logs when the 'Issue_Description' involves 'Motor overheating and failure to start', we can join the production_logs and maintenance_logs tables based on the machine name and maintenance type. Then, we can calculate the total downtime in minutes and hours separately for each combination of machine and maintenance type. Finally, we can find the machines with both downtime minutes and hours greater than zero.\n\nHere's the SQL query:\n\n```sql\nSELECT pl.Machine, pl.Maintenance_Type, SUM(pl.Downtime_Minutes) AS Downtime_Minutes, SUM(ml.Downtime_Hours * 60) AS Downtime_Hours\nFROM production_logs pl\nINNER JOIN maintenance_logs ml ON pl.Machine = ml.Machine AND pl.Maintenance_Type = ml.Maintenance_Type\nWHERE pl.Maintenance_Type = 'Breakdown' AND ml.Issue_Description LIKE '%Motor overheating and failure to start%'\nGROUP BY pl.Machine, pl.Maintenance_Type\nHAVING SUM(pl.Downtime_Minutes) > 0 AND SUM(ml.Downtime_Hours * 60) > 0;\n```\n\nThis query joins the production_logs and maintenance_logs tables on the Machine and Maintenance_Type columns. We filter the results for breakdown maintenance types and search for the specific issue description. Then, we group the results by Machine and Maintenance_Type and apply the HAVING clause to filter for machines with both downtime minutes and hours greater than zero. The result will show the machines with the specified issue and their total downtime in minutes and hours. ",
    "table_selection_response": "{\n  \"tables\": [\n    \"production_logs\",\n    \"maintenance_logs\"\n  ],\n  \"columns\": [\n    \"Downtime_Minutes\",\n    \"Downtime_Hours\"\n  ]\n} ",
    "methodology_score": 59.09090909090909,
    "sql_score": 51.67483489746263,
    "table_column_score": 74.28571428571429,
    "response_quality_score": 87.93469309806824,
    "overall_score": 63.17836282262004,
    "methodology_details": {
      "method": "keyword_fallback",
      "overlap_count": 13,
      "expected_keyword_count": 22,
      "response_keyword_count": 82
    },
    "sql_details": {
      "table_match": 100.0,
      "column_match": 16.666666666666664,
      "aggregate_match": 33.33333333333333,
      "clause_match": 57.14285714285714,
      "fuzzy_score": 48.46715328467154,
      "overall_score": 51.67483489746263,
      "expected_tables": [
        "maintenance_logs",
        "production_logs"
      ],
      "generated_tables": [
        "maintenance_logs",
        "production_logs"
      ],
      "expected_columns": [
        "downtime_hours",
        "downtime_minutes"
      ],
      "generated_columns": [
        "pl",
        "downtime_minutes",
        "maintenance_type",
        "downtime_hours * 60",
        "machine"
      ],
      "has_valid_sql": true
    },
    "table_column_details": {
      "overall_score": 74.28571428571429,
      "table_score": 100.0,
      "column_score": 57.14285714285715,
      "table_precision": 100.0,
      "table_recall": 100.0,
      "column_precision": 100.0,
      "column_recall": 40.0,
      "tables_correct": [
        "maintenance_logs",
        "production_logs"
      ],
      "tables_missing": [],
      "tables_extra": [],
      "columns_correct": [
        "downtime_hours",
        "downtime_minutes"
      ],
      "columns_missing": [
        "breakdown_date",
        "date",
        "issue_description"
      ],
      "columns_extra": [],
      "expected_tables": [
        "maintenance_logs",
        "production_logs"
      ],
      "generated_tables": [
        "maintenance_logs",
        "production_logs"
      ],
      "expected_columns": [
        "date",
        "downtime_minutes",
        "breakdown_date",
        "issue_description",
        "downtime_hours"
      ],
      "generated_columns": [
        "downtime_hours",
        "downtime_minutes"
      ]
    },
    "total_latency_ms": 12065.306901931763,
    "total_tokens": 3046,
    "errors": [],
    "timestamp": "2025-11-30T13:13:10.936361"
  },
  {
    "question_id": "Complex_3",
    "question_text": "What is the correlation between downtime minutes and failed quantity per line machine and product?",
    "category": "Complex",
    "model_id": "allam-2-7b",
    "methodology_response": "To answer the question about the correlation between downtime minutes and failed quantity per line machine and product, we will follow these steps:\n\n1. Connect to the SQL database and select the required tables:\n   ```sql\n   SELECT production_logs.*, quality_control.*, maintenance_logs.*, inventory_logs.*\n   ```\n\n2. Filter the data based on the manufacturing date and product:\n   ```sql\n   WHERE production_logs.Date = 'YYYY-MM-DD' AND quality_control.Product = 'PRODUCT_CODE'\n   ```\n\n3. Calculate the total downtime minutes for each line machine and product combination:\n   ```sql\n   SUM(production_logs.Downtime_Minutes) AS Total_Downtime_Minutes\n   ```\n\n4. Calculate the total failed quantity for each line machine and product combination:\n   ```sql\n   SUM(quality_control.Failed_Qty) AS Total_Failed_Qty\n   ```\n\n5. Group the data by line machine, product, and manufacturing date:\n   ```sql\n   GROUP BY production_logs.Line_Machine, quality_control.Product, production_logs.Date\n   ```\n\n6. Join the calculated total downtime minutes and total failed quantity with the line machine, product, and manufacturing date data:\n   ```sql\n   JOIN (SELECT SUM(production_logs.Downtime_Minutes) AS Total_Downtime_Minutes, production_logs.Line_Machine, quality_control.Product, production_logs.Date\n       FROM production_logs\n       GROUP BY production_logs.Line_Machine, quality_control.Product, production_logs.Date) AS downtime_minutes ON downtime_minutes.Line_Machine = production_logs.Line_Machine AND downtime_minutes.Product = quality_control.Product AND downtime_minutes.Date = production_logs.Date\n   ```\n\n7. Join the calculated total downtime minutes and total failed quantity with the maintenance logs table to get the breakdown of downtime minutes by machine and product:\n   ```sql\n   JOIN maintenance_logs ON maintenance_logs.Line_Machine = downtime_minutes.Line_Machine AND maintenance_logs.Product = downtime_minutes.Product\n   ```\n\n8. Calculate the correlation coefficient between downtime minutes and failed quantity:\n   ```sql\n   CORR(downtime_minutes.Total_Downtime_Minutes, downtime_minutes.Total_Failed_Qty) AS Correlation_Coefficient\n   ```\n\n9. Filter the data for a specific date range:\n   ```sql\n   WHERE downtime_minutes.Date BETWEEN 'START_DATE' AND 'END_DATE'\n   ```\n\n10. Filter the data for a specific product:\n    ```sql\n    WHERE downtime_minutes.Product = 'PRODUCT_CODE'\n    ```\n\n11. Filter the data for a specific line machine:\n    ```sql\n    WHERE downtime_minutes.Line_Machine = 'LINE_CODE'\n    ```\n\n12. Calculate the average downtime minutes and failed quantity for each combination of line machine, product, and date:\n    ```sql\n    SELECT AVG(downtime_minutes.Total_Downtime_Minutes) AS Avg_Downtime_Minutes, AVG(downtime_minutes.Total_Failed_Qty) AS Avg_Failed_Qty, downtime_minutes.Line_Machine, downtime_minutes.Product, downtime_minutes.Date\n    ```\n\n13. Calculate the correlation coefficient between downtime minutes and failed quantity:\n    ```sql\n    CORR(downtime_minutes.Total_Downtime_Minutes, downtime_minutes.Total_Failed_Qty) AS Correlation_Coefficient\n    ```\n\n14. Display the results:\n    ```sql\n    SELECT downtime_minutes.Line_Machine, downtime_minutes.Product, downtime_minutes.Date, downtime_",
    "sql_response": "To find the correlation between downtime minutes and failed quantity per line machine and product, we can join the `production_logs` and `quality_control` tables on the common columns `Line_Machine` and `Product`, and then calculate the downtime minutes and failed quantity for each combination. We can then calculate the average downtime minutes per failed quantity using a subquery. Here's the SQL query:\n\n```sql\nSELECT\n    production_logs.Line_Machine,\n    production_logs.Product,\n    AVG(quality_control.Downtime_Minutes) AS Avg_Downtime_Minutes_Per_Failed_Qty,\n    AVG(quality_control.Failed_Qty) AS Avg_Failed_Qty_Per_Line_Machine_Product\nFROM\n    production_logs\nJOIN quality_control ON production_logs.Line_Machine = quality_control.Line_Machine AND production_logs.Product = quality_control.Product\nGROUP BY\n    production_logs.Line_Machine,\n    production_logs.Product;\n```\n\nThis query joins the `production_logs` and `quality_control` tables on the common columns `Line_Machine` and `Product`, and calculates the average downtime minutes per failed quantity using the `AVG` function. The result will include the line machine, product, and the average downtime minutes per failed quantity for each combination of line machine and product. ",
    "table_selection_response": "{\n  \"tables\": [\n    \"production_logs\",\n    \"quality_control\"\n  ],\n  \"columns\": [\n    \"Product\",\n    \"Actual_Qty\",\n    \"Failed_Qty\",\n    \"Line_Machine\"\n  ]\n} ",
    "methodology_score": 72.72727272727273,
    "sql_score": 63.451767304860084,
    "table_column_score": 70.0,
    "response_quality_score": 86.3068642616272,
    "overall_score": 70.15698680104556,
    "methodology_details": {
      "method": "keyword_fallback",
      "overlap_count": 8,
      "expected_keyword_count": 11,
      "response_keyword_count": 101
    },
    "sql_details": {
      "table_match": 100.0,
      "column_match": 40.0,
      "aggregate_match": 50.0,
      "clause_match": 75.0,
      "fuzzy_score": 48.01178203240058,
      "overall_score": 63.451767304860084,
      "expected_tables": [
        "production_logs",
        "quality_control"
      ],
      "generated_tables": [
        "production_logs",
        "quality_control"
      ],
      "expected_columns": [
        "downtime_minutes",
        "failed_qty"
      ],
      "generated_columns": [
        "line_machine",
        "production_logs",
        "product",
        "downtime_minutes",
        "failed_qty"
      ],
      "has_valid_sql": true
    },
    "table_column_details": {
      "overall_score": 70.0,
      "table_score": 100.0,
      "column_score": 50.0,
      "table_precision": 100.0,
      "table_recall": 100.0,
      "column_precision": 50.0,
      "column_recall": 50.0,
      "tables_correct": [
        "production_logs",
        "quality_control"
      ],
      "tables_missing": [],
      "tables_extra": [],
      "columns_correct": [
        "product",
        "failed_qty"
      ],
      "columns_missing": [
        "date",
        "downtime_minutes"
      ],
      "columns_extra": [
        "line_machine",
        "actual_qty"
      ],
      "expected_tables": [
        "production_logs",
        "quality_control"
      ],
      "generated_tables": [
        "production_logs",
        "quality_control"
      ],
      "expected_columns": [
        "product",
        "date",
        "downtime_minutes",
        "failed_qty"
      ],
      "generated_columns": [
        "product",
        "line_machine",
        "actual_qty",
        "failed_qty"
      ]
    },
    "total_latency_ms": 13693.135738372803,
    "total_tokens": 2913,
    "errors": [],
    "timestamp": "2025-11-30T13:13:31.127942"
  },
  {
    "question_id": "Easy_26",
    "question_text": "What is the average target quantity for all products?",
    "category": "Easy",
    "model_id": "allam-2-7b",
    "methodology_response": "To find the average target quantity for all products, we will follow these steps:\n\n1. Connect to the database and select the necessary tables:\n   ```sql\n   SELECT production_logs, quality_control, inventory_logs\n   ```\n\n2. Filter the production_logs table to include only the target quantity column:\n   ```sql\n   SELECT production_logs.*\n   WHERE production_logs.Target_Qty IS NOT NULL\n   ```\n\n3. Filter the quality_control table to include only the relevant columns:\n   ```sql\n   SELECT quality_control.*\n   WHERE quality_control.Product IS NOT NULL\n   ```\n\n4. Filter the inventory_logs table to include only the relevant columns:\n   ```sql\n   SELECT inventory_logs.*\n   WHERE inventory_logs.Product IS NOT NULL\n   ```\n\n5. Combine the filtered data from the three tables using a JOIN operation:\n   ```sql\n   SELECT production_logs.Product, quality_control.Product, inventory_logs.Product,\n          SUM(production_logs.Target_Qty), SUM(quality_control.Passed_Qty), SUM(inventory_logs.Consumption_Kg) AS Total_Consumption\n   FROM production_logs\n   JOIN quality_control ON production_logs.Product = quality_control.Product\n   JOIN inventory_logs ON production_logs.Product = inventory_logs.Product\n   GROUP BY production_logs.Product, quality_control.Product, inventory_logs.Product\n   ```\n\n6. Calculate the average target quantity for each product:\n   ```sql\n   SELECT production_logs.Product, AVG(production_logs.Target_Qty) AS Avg_Target_Qty\n   FROM production_logs\n   GROUP BY production_logs.Product\n   ```\n\n7. Calculate the total consumption for each product:\n   ```sql\n   SELECT production_logs.Product, SUM(inventory_logs.Consumption_Kg) AS Total_Consumption\n   FROM production_logs\n   JOIN inventory_logs ON production_logs.Product = inventory_logs.Product\n   GROUP BY production_logs.Product\n   ```\n\n8. Calculate the average target quantity and total consumption for all products:\n   ```sql\n   SELECT AVG(avg_target_qty.Avg_Target_Qty), avg_target_qty.Total_Consumption\n   FROM (\n       SELECT production_logs.Product, AVG(production_logs.Target_Qty) AS Avg_Target_Qty\n       FROM production_logs\n       GROUP BY production_logs.Product\n   ) AS avg_target_qty\n   JOIN (\n       SELECT production_logs.Product, SUM(inventory_logs.Consumption_Kg) AS Total_Consumption\n       FROM production_logs\n       JOIN inventory_logs ON production_logs.Product = inventory_logs.Product\n       GROUP BY production_logs.Product\n   ) AS avg_target_qty\n   ```\n\n9. Combine the results from steps 8 and 7:\n   ```sql\n   SELECT avg_target_qty.Avg_Target_Qty, avg_target_qty.Total_Consumption, total_consumption.Total_Consumption\n   FROM (\n       SELECT production_logs.Product, AVG(production_logs.Target_Qty) AS Avg_Target_Qty\n       FROM production_logs\n       GROUP BY production_logs.Product\n   ) AS avg_target_qty\n   JOIN (\n       SELECT production_logs.Product, SUM(inventory_logs.Consumption_Kg) AS Total_Consumption\n       FROM production_logs\n   ",
    "sql_response": "To find the average target quantity for all products, we can use the following SQL query:\n\n```sql\nSELECT AVG(Actual_Qty) AS Average_Target_Qty\nFROM (\n  SELECT Production_Logs.Product, SUM(Production_Logs.Actual_Qty) AS Actual_Qty\n  FROM Production_Logs\n  JOIN production_lines ON Production_Logs.Line_Machine = production_lines.Line_Machine\n  GROUP BY Production_Logs.Product\n) Production_Data;\n```\n\nThis query first calculates the sum of actual quantities for each product by joining the `Production_Logs` table with the `production_lines` table on the `Line_Machine` column. Then, it groups the results by `Product` and calculates the sum of actual quantities using the `SUM()` function. Finally, it calculates the average of these sums using the `AVG()` function and aliases the result as `Average_Target_Qty`. ",
    "table_selection_response": "{\n  \"tables\": [\n    \"production_logs\"\n  ],\n  \"columns\": [\n    \"Product\",\n    \"Target_Qty\"\n  ]\n} ",
    "methodology_score": 60.0,
    "sql_score": 46.30664652567976,
    "table_column_score": 80.0,
    "response_quality_score": 88.31932806968689,
    "overall_score": 63.0392590909566,
    "methodology_details": {
      "method": "keyword_fallback",
      "overlap_count": 3,
      "expected_keyword_count": 5,
      "response_keyword_count": 69
    },
    "sql_details": {
      "table_match": 100.0,
      "column_match": 0.0,
      "aggregate_match": 50.0,
      "clause_match": 50.0,
      "fuzzy_score": 25.377643504531722,
      "overall_score": 46.30664652567976,
      "expected_tables": [
        "production_logs"
      ],
      "generated_tables": [
        "production_logs"
      ],
      "expected_columns": [
        "target_qty"
      ],
      "generated_columns": [
        "product",
        "production_logs",
        "actual_qty"
      ],
      "has_valid_sql": true
    },
    "table_column_details": {
      "overall_score": 80.0,
      "table_score": 100.0,
      "column_score": 66.66666666666666,
      "table_precision": 100.0,
      "table_recall": 100.0,
      "column_precision": 50.0,
      "column_recall": 100.0,
      "tables_correct": [
        "production_logs"
      ],
      "tables_missing": [],
      "tables_extra": [],
      "columns_correct": [
        "target_qty"
      ],
      "columns_missing": [],
      "columns_extra": [
        "product"
      ],
      "expected_tables": [
        "production_logs"
      ],
      "generated_tables": [
        "production_logs"
      ],
      "expected_columns": [
        "target_qty"
      ],
      "generated_columns": [
        "product",
        "target_qty"
      ]
    },
    "total_latency_ms": 11680.67193031311,
    "total_tokens": 2737,
    "errors": [],
    "timestamp": "2025-11-30T13:13:50.479762"
  },
  {
    "question_id": "Complex_24",
    "question_text": "For Material Steel-101, what is the trend of wastage (increase or decrease) over the past 6 months?",
    "category": "Complex",
    "model_id": "allam-2-7b",
    "methodology_response": "To answer the question about the trend of wastage for Material Steel-101 over the past 6 months, we will follow these steps:\n\n1. Connect to the SQL database and select the required tables:\n   - Production_logs table to get the production data\n   - Quality_control table to get the inspection data\n   - Maintenance_logs table to get the maintenance data\n   - Inventory_logs table to get the inventory data\n\n2. Filter the data for the past 6 months:\n   - Select only the rows where the date is within the last 6 months\n\n3. Calculate the consumption and wastage:\n   - Calculate the consumption of Steel-101 material by subtracting the opening stock from the consumption and adding the received stock:\n     ```sql\n     SELECT Production_logs.Date,\n            SUM(Production_logs.Actual_Qty) AS Consumption,\n            SUM(Inventory_logs.Consumption_Kg) AS Received_Wastage\n     FROM Production_logs\n     JOIN Inventory_logs ON Production_logs.Date = Inventory_logs.Date\n     WHERE Production_logs.Material_Code = 'Steel-101'\n     GROUP BY Production_logs.Date\n     ```\n\n4. Calculate the total consumption and wastage:\n   - Sum the consumption and wastage calculated in step 3:\n     ```sql\n     SELECT SUM(Consumption) AS Total_Consumption,\n            SUM(Received_Wastage) AS Total_Wastage\n     FROM (\n         SELECT Production_logs.Date,\n                SUM(Production_logs.Actual_Qty) AS Consumption,\n                SUM(Inventory_logs.Consumption_Kg) AS Received_Wastage\n         FROM Production_logs\n         JOIN Inventory_logs ON Production_logs.Date = Inventory_logs.Date\n         WHERE Production_logs.Material_Code = 'Steel-101'\n         GROUP BY Production_logs.Date\n     ) AS Consumption_and_Wastage\n     ```\n\n5. Calculate the wastage rate:\n   - Calculate the wastage rate by dividing the total wastage by the total consumption:\n     ```sql\n     SELECT Total_Consumption, Total_Wastage, Total_Consumption / Total_Wastage AS Wastage_Rate\n     FROM (\n         SELECT SUM(Consumption_and_Wastage.Total_Consumption) AS Total_Consumption,\n                SUM(Consumption_and_Wastage.Total_Wastage) AS Total_Wastage\n         FROM (\n             SELECT Production_logs.Date,\n                    SUM(Production_logs.Actual_Qty) AS Consumption_and_Wastage,\n                    SUM(Inventory_logs.Consumption_Kg) AS Total_Wastage\n             FROM Production_logs\n             JOIN Inventory_logs ON Production_logs.Date = Inventory_logs.Date\n             WHERE Production_logs.Material_Code = 'Steel-101'\n             GROUP BY Production_logs.Date\n ",
    "sql_response": "To find the trend of wastage for Material Steel-101 over the past 6 months, we can use the following SQL query:\n\n```sql\nSELECT \n    Date,\n    SUM(Wastage_Kg) AS Total_Wastage_Kg,\n    CASE\n        WHEN Date >= DATEADD(month, -6, GETDATE()) THEN 'Decrease'\n        ELSE 'Increase'\n    END AS Wastage_Trend\nFROM \n    (\n        SELECT \n            Date,\n            Material_Code,\n            SUM(Wastage_Kg) AS Wastage_Kg\n        FROM inventory_logs\n        GROUP BY Date, Material_Code\n    ) AS Inventory_Logs\nGROUP BY Date, Material_Code\nORDER BY Date;\n```\n\nThis query will give us the following information:\n\n1. The date for each record\n2. The total wastage in kilograms for the given material over the specified period\n3. Whether the wastage trend is increasing or decreasing (based on the date)\n\nThe inner query calculates the total wastage for each date and material combination, and the outer query groups the results by date and material, and orders the results by date. ",
    "table_selection_response": "{\n  \"tables\": [\n    \"inventory_logs\"\n  ],\n  \"columns\": [\n    \"Wastage_Kg\"\n  ]\n} ",
    "methodology_score": 52.38095238095239,
    "sql_score": 71.0944976076555,
    "table_column_score": 70.0,
    "response_quality_score": 87.5438826084137,
    "overall_score": 66.85174813780651,
    "methodology_details": {
      "method": "keyword_fallback",
      "overlap_count": 11,
      "expected_keyword_count": 21,
      "response_keyword_count": 80
    },
    "sql_details": {
      "table_match": 100.0,
      "column_match": 27.27272727272727,
      "aggregate_match": 100.0,
      "clause_match": 66.66666666666666,
      "fuzzy_score": 61.8421052631579,
      "overall_score": 71.0944976076555,
      "expected_tables": [
        "inventory_logs"
      ],
      "generated_tables": [
        "inventory_logs"
      ],
      "expected_columns": [
        "wastage_kg",
        "material_code",
        "strftime",
        "date",
        "strftime%y-%m",
        "totalwastage",
        "case when select totalwastage",
        "month"
      ],
      "generated_columns": [
        "wastage_kg",
        "material_code",
        "getdate then decrease else increase end",
        "date",
        "case when date >= dateaddmonth",
        "-6"
      ],
      "has_valid_sql": true
    },
    "table_column_details": {
      "overall_score": 70.0,
      "table_score": 100.0,
      "column_score": 50.0,
      "table_precision": 100.0,
      "table_recall": 100.0,
      "column_precision": 100.0,
      "column_recall": 33.33333333333333,
      "tables_correct": [
        "inventory_logs"
      ],
      "tables_missing": [],
      "tables_extra": [],
      "columns_correct": [
        "wastage_kg"
      ],
      "columns_missing": [
        "material_code",
        "date"
      ],
      "columns_extra": [],
      "expected_tables": [
        "inventory_logs"
      ],
      "generated_tables": [
        "inventory_logs"
      ],
      "expected_columns": [
        "material_code",
        "wastage_kg",
        "date"
      ],
      "generated_columns": [
        "wastage_kg"
      ]
    },
    "total_latency_ms": 12456.117391586304,
    "total_tokens": 2910,
    "errors": [],
    "timestamp": "2025-11-30T13:14:09.688756"
  },
  {
    "question_id": "Medium_20",
    "question_text": "Which supplier had the lowest average unit cost for 'Rubber-RB' in the last 6 months?",
    "category": "Medium",
    "model_id": "allam-2-7b",
    "methodology_response": "To answer the question about the lowest average unit cost for the material 'Rubber-RB' in the last 6 months, we will follow these steps:\n\n1. Connect to the database and select the necessary tables:\n   - Production logs (production_logs) to get the consumption data\n   - Quality control (quality_control) to get the supplier information\n   - Maintenance logs (maintenance_logs) to get the breakdown dates\n   - Inventory logs (inventory_logs) to get the supplier information and unit cost\n\n2. Filter the data for the last 6 months:\n   - Production logs: Select rows where Date >= DATEADD(month, -6, GETDATE())\n   - Quality control: Select rows where Inspection_Date >= DATEADD(month, -6, GETDATE())\n   - Maintenance logs: Select rows where Maintenance_Date >= DATEADD(month, -6, GETDATE())\n   - Inventory logs: Select rows where Date >= DATEADD(month, -6, GETDATE())\n\n3. Join the tables on the common columns:\n   - Production logs and quality control: Join on Product and Inspection_Date\n   - Production logs and inventory logs: Join on Product and Date\n   - Quality control and inventory logs: Join on Product and Inspection_Date\n\n4. Calculate the consumption quantity for each supplier:\n   - Calculate the SUM(Consumption_Kg) for each supplier in the joined table.\n\n5. Calculate the total cost for each supplier:\n   - Calculate the SUM(Unit_Cost * Consumption_Kg) for each supplier in the joined table.\n\n6. Calculate the average unit cost for each supplier:\n   - Calculate the AVG(Total_Cost) for each supplier in the joined table.\n\n7. Sort the data by average unit cost in descending order:\n   - Sort the data by Average_Unit_Cost DESC.\n\n8. Select the first row(s) to find the supplier with the lowest average unit cost:\n   - Select the first row(s) from the sorted data to find the supplier with the lowest average unit cost.\n\n9. Display the supplier name and average unit cost:\n   - Select the Supplier_Name and Average_Unit_Cost from the selected rows.\n\nLet's assume the SQL query to perform these steps would look like this:\n\n```sql\nSELECT\n    s.Supplier_Name,\n    AVG(t.Average_Unit_Cost) AS Average_Unit_Cost\nFROM\n    (\n        SELECT\n            p.Supplier_Name,\n            SUM(p.Consumption_Kg) AS Consumption_Kg,\n            SUM(p.Unit_Cost * p.Consumption_Kg) AS Total_Cost\n        FROM\n            production_logs p\n            INNER JOIN quality_control q ON p.Product = q.Product AND p.Inspection_Date = q.Inspection_Date\n            INNER JOIN inventory_logs i ON p.Product = i.Product AND p.Inspection_Date = i.Inspection_Date\n        GROUP BY p.Product, q.Product, i.Product\n        HAVING COUNT(DISTINCT i.Inspection_Date) >= 6\n    ) AS t\n    INNER JOIN suppliers s ON t.Product = s.Product\nGROUP BY s.Supplier_Name\nORDER BY t.Average_Unit_Cost DESC\nLIMIT 1;\n```\n\nThis query will retrieve the supplier with the lowest average unit cost for the product 'Rubber-RB' over the last 6 inspections. Then, it will group the data by supplier and order it by the average unit cost in descending order, and finally, limit the result to only one row to get the supplier with the lowest average unit cost. ",
    "sql_response": "To find the supplier with the lowest average unit cost for 'Rubber-RB' in the last 6 months, we can use the following SQL query:\n\n```sql\nSELECT s.Supplier, AVG(il.Unit_Cost_Rupees) AS Avg_Unit_Cost\nFROM inventory_logs il\nJOIN inventory i ON il.Material_Code = i.Material_Code\nJOIN suppliers s ON i.Supplier = s.Supplier_Code\nWHERE il.Material_Code = 'Rubber-RB' AND il.Date >= DATEADD(month, -6, GETDATE())\nGROUP BY s.Supplier, il.Unit_Cost_Rupees\nORDER BY s.Supplier, Avg_Unit_Cost ASC;\n```\n\nThis query joins the `inventory_logs`, `inventory`, and `suppliers` tables based on the `Material_Code`, `Material_Code`, and `Supplier_Code` columns respectively. We filter the results for 'Rubber-RB' and the date range of the last 6 months using `DATEADD(month, -6, GETDATE())`. Finally, we group the results by supplier and average unit cost, and sort the suppliers and their average unit costs in ascending order. ",
    "table_selection_response": "{\n  \"tables\": [\n    \"inventory_logs\",\n    \"production_logs\"\n  ],\n  \"columns\": [\n    \"Material_Code\",\n    \"Unit_Cost_Rupees\",\n    \"Product\",\n    \"Opening_Stock_Kg\",\n    \"Consumption_Kg\",\n    \"Received_Kg\",\n    \"Closing_Stock_Kg\",\n    \"Wastage_Kg\"\n  ]\n} ",
    "methodology_score": 88.23529411764706,
    "sql_score": 74.73129894679988,
    "table_column_score": 46.666666666666664,
    "response_quality_score": 87.27624726295471,
    "overall_score": 73.0208342596362,
    "methodology_details": {
      "method": "keyword_fallback",
      "overlap_count": 15,
      "expected_keyword_count": 17,
      "response_keyword_count": 134
    },
    "sql_details": {
      "table_match": 100.0,
      "column_match": 40.0,
      "aggregate_match": 100.0,
      "clause_match": 71.42857142857143,
      "fuzzy_score": 60.113421550094515,
      "overall_score": 74.73129894679988,
      "expected_tables": [
        "inventory_logs"
      ],
      "generated_tables": [
        "inventory_logs"
      ],
      "expected_columns": [
        "material_code",
        "unit_cost_rupees",
        "supplier",
        "avgcost"
      ],
      "generated_columns": [
        "s",
        "unit_cost_rupees",
        "supplier"
      ],
      "has_valid_sql": true
    },
    "table_column_details": {
      "overall_score": 46.666666666666664,
      "table_score": 66.66666666666666,
      "column_score": 33.33333333333333,
      "table_precision": 50.0,
      "table_recall": 100.0,
      "column_precision": 25.0,
      "column_recall": 50.0,
      "tables_correct": [
        "inventory_logs"
      ],
      "tables_missing": [],
      "tables_extra": [
        "production_logs"
      ],
      "columns_correct": [
        "material_code",
        "unit_cost_rupees"
      ],
      "columns_missing": [
        "supplier",
        "date"
      ],
      "columns_extra": [
        "wastage_kg",
        "closing_stock_kg",
        "product",
        "opening_stock_kg",
        "consumption_kg",
        "received_kg"
      ],
      "expected_tables": [
        "inventory_logs"
      ],
      "generated_tables": [
        "inventory_logs",
        "production_logs"
      ],
      "expected_columns": [
        "material_code",
        "unit_cost_rupees",
        "supplier",
        "date"
      ],
      "generated_columns": [
        "material_code",
        "wastage_kg",
        "closing_stock_kg",
        "product",
        "opening_stock_kg",
        "unit_cost_rupees",
        "consumption_kg",
        "received_kg"
      ]
    },
    "total_latency_ms": 12723.752737045288,
    "total_tokens": 2924,
    "errors": [],
    "timestamp": "2025-11-30T13:14:28.968322"
  },
  {
    "question_id": "Complex_29",
    "question_text": "How does the rework count vary by defect type and product?",
    "category": "Complex",
    "model_id": "allam-2-7b",
    "methodology_response": "To answer the question about how the rework count varies by defect type and product, we will follow these steps:\n\n1. Connect to the database and select the required tables:\n   - Production Logs (production_logs) to get the product and defect type information\n   - Quality Control (quality_control) to get the defect type information\n   - Maintenance Logs (maintenance_logs) to get the breakdown date and machine information\n   - Inventory Logs (inventory_logs) to get the product information\n\n2. Filter the Production Logs table to get the data for the specific product and defect type combinations:\n   - Filter production_logs table by product and defect type.\n\n3. Filter the Quality Control table to get the defect type information:\n   - Filter quality_control table by defect type.\n\n4. Filter the Maintenance Logs table to get the breakdown date and machine information:\n   - Filter maintenance_logs table by breakdown date and machine.\n\n5. Filter the Inventory Logs table to get the product information:\n   - Filter inventory_logs table by product.\n\n6. Join the filtered tables based on the common columns (product and defect type) to get the required data:\n   - Join production_logs, quality_control, maintenance_logs, and inventory_logs tables based on product and defect type.\n\n7. Calculate the rework count for each combination of product and defect type:\n   - Calculate the SUM(rework_count) for each combination of product and defect type.\n\n8. Calculate the total production quantity for each combination of product and defect type:\n   - Calculate the SUM(actual_qty) for each combination of product and defect type.\n\n9. Calculate the total quality inspection quantity for each combination of product and defect type:\n   - Calculate the SUM(inspected_qty) for each combination of product and defect type.\n\n10. Calculate the total breakdown quantity for each combination of product and defect type:\n    - Calculate the SUM(breakdown_qty) for each combination of product and defect type.\n\n11. Calculate the total maintenance quantity for each combination of product and defect type:\n    - Calculate the SUM(maintenance_qty) for each combination of product and defect type.\n\n12. Calculate the total inventory quantity for each combination of product and defect type:\n    - Calculate the SUM(inventory_qty) for each combination of product and defect type.\n\n13. Calculate the total rework quantity for each combination of product and defect type:\n    - Calculate the SUM(rework_qty) for each combination of product and defect type.\n\n14. Calculate the total defective quantity for each combination of product and defect type:\n    - Calculate the SUM(defective_qty) for each combination of product and defect type.\n\n15. Calculate the rework rate for each combination of product and defect type:\n    - Calculate the RATIO(rework_qty, defective_qty) for each combination of product and defect type.\n\n16. Calculate the rework rate for each combination of product and defect type:\n    - Calculate the RATIO(rework_qty, defective_qty) for each combination of product and defect type.\n\n17. Calculate the rework efficiency for each combination of product and defect type:\n    - Calculate the RATIO(rework_qty, defective_qty) for each combination of product and defect type.\n\n18. Calculate the rework productivity for each combination of product and defect type:\n    - Calculate the RATIO(rework_qty, defective_qty) for each combination of product and defect type.\n\n19. Calculate the rework efficiency and productivity for each combination of product and defect type:\n    - Calculate the RATIO(rework_qty, defective_qty) for each combination of product and defect type.\n\n20. Calculate the rework efficiency and productivity for each combination of product and defect type:\n    - Calculate the RATIO(rework_qty, defective_qty) for each combination of product and defect type.\n\n21. Calculate the rework efficiency and productivity for each combination of product and defect type:\n    - Calculate the RATIO(rework_qty, defective_qty) for each combination of product and defect type.\n\n22",
    "sql_response": "To find the rework count variation by defect type and product, we can use a combination of JOINs and GROUP BY clauses in our SQL query. Here's the query:\n\n```sql\nSELECT maintenance_logs.Machine, quality_control.Defect_Type, quality_control.Product, SUM(inventory_logs.Consumption_Kg) AS Rework_Count\nFROM maintenance_logs\nJOIN quality_control ON maintenance_logs.Machine = quality_control.Machine\nJOIN inventory_logs ON maintenance_logs.Machine = inventory_logs.Machine\nGROUP BY maintenance_logs.Machine, quality_control.Defect_Type, quality_control.Product;\n```\n\nThis query joins the `maintenance_logs`, `quality_control`, and `inventory_logs` tables on the `Machine` column. Then, it calculates the sum of `Consumption_Kg` from the `inventory_logs` table for each combination of `Machine`, `Defect_Type`, and `Product`. Finally, the result is grouped by `Machine`, `Defect_Type`, and `Product`. ",
    "table_selection_response": "{\n  \"tables\": [\n    \"quality_control\",\n    \"production_logs\"\n  ],\n  \"columns\": [\n    \"Product\",\n    \"Rework_Count\"\n  ]\n} ",
    "methodology_score": 55.55555555555556,
    "sql_score": 39.32978363759297,
    "table_column_score": 74.66666666666666,
    "response_quality_score": 88.52699089050293,
    "overall_score": 57.95145669554117,
    "methodology_details": {
      "method": "keyword_fallback",
      "overlap_count": 5,
      "expected_keyword_count": 9,
      "response_keyword_count": 92
    },
    "sql_details": {
      "table_match": 33.33333333333333,
      "column_match": 33.33333333333333,
      "aggregate_match": 33.33333333333333,
      "clause_match": 75.0,
      "fuzzy_score": 31.64300202839757,
      "overall_score": 39.32978363759297,
      "expected_tables": [
        "quality_control"
      ],
      "generated_tables": [
        "maintenance_logs",
        "quality_control",
        "inventory_logs"
      ],
      "expected_columns": [
        "product",
        "defect_type",
        "rework_count"
      ],
      "generated_columns": [
        "product",
        "defect_type",
        "maintenance_logs",
        "consumption_kg",
        "machine"
      ],
      "has_valid_sql": true
    },
    "table_column_details": {
      "overall_score": 74.66666666666666,
      "table_score": 66.66666666666666,
      "column_score": 80.0,
      "table_precision": 50.0,
      "table_recall": 100.0,
      "column_precision": 100.0,
      "column_recall": 66.66666666666666,
      "tables_correct": [
        "quality_control"
      ],
      "tables_missing": [],
      "tables_extra": [
        "production_logs"
      ],
      "columns_correct": [
        "product",
        "rework_count"
      ],
      "columns_missing": [
        "defect_type"
      ],
      "columns_extra": [],
      "expected_tables": [
        "quality_control"
      ],
      "generated_tables": [
        "production_logs",
        "quality_control"
      ],
      "expected_columns": [
        "product",
        "defect_type",
        "rework_count"
      ],
      "generated_columns": [
        "product",
        "rework_count"
      ]
    },
    "total_latency_ms": 11473.00910949707,
    "total_tokens": 2805,
    "errors": [],
    "timestamp": "2025-11-30T13:14:46.906972"
  },
  {
    "question_id": "Medium_24",
    "question_text": "Which material has the highest wastage (in Kg) from July 2026 to Dec 2026?",
    "category": "Medium",
    "model_id": "allam-2-7b",
    "methodology_response": "To answer the question about the material with the highest wastage from July 2026 to Dec 2026, we will follow these steps:\n\n1. Connect to the SQL database and select the necessary tables:\n   - Production_logs table to get the consumption data\n   - Quality_control table to get the material information\n   - Maintenance_logs table to get the breakdown dates\n   - Inventory_logs table to get the wastage data\n\n2. Filter the data for the specified period (July 2026 to Dec 2026):\n   - Production_logs table: Filter by Date between '2026-07-01' and '2026-12-31'\n   - Quality_control table: Filter by Inspection_Date between '2026-07-01' and '2026-12-31'\n   - Maintenance_logs table: Filter by Maintenance_Date between '2026-07-01' and '2026-12-31'\n   - Inventory_logs table: Filter by Date between '2026-07-01' and '2026-12-31'\n\n3. Join the filtered tables to get the required data:\n   - Join Production_logs, Quality_control, Maintenance_logs, and Inventory_logs tables on Material_Code\n\n4. Calculate the consumption and wastage for each material:\n   - Calculate the consumption for each material by summing the Consumption_Kg column from Production_logs table\n   - Calculate the wastage for each material by summing the Wastage_Kg column from Inventory_logs table\n\n5. Calculate the total consumption and wastage for each material:\n   - Sum the consumption and wastage for each material\n\n6. Sort the data by wastage in descending order:\n   - Sort the data based on the total wastage in descending order\n\n7. Select the top 1 row to find the material with the highest wastage:\n   - Select the row with the highest total wastage\n\n8. Display the material name and total wastage:\n   - Retrieve the Material_Code and Total_Wastage from the selected row\n\nHere is the SQL query to perform these steps:\n\n```sql\nSELECT\n    Production_logs.Material_Code,\n    SUM(Production_logs.Consumption_Kg) AS Total_Consumption,\n    SUM(Inventory_logs.Wastage_Kg) AS Total_Wastage\nFROM\n    Production_logs\n    INNER JOIN Quality_control ON Production_logs.Material_Code = Quality_control.Material_Code\n    INNER JOIN Maintenance_logs ON Production_logs.Material_Code = Maintenance_logs.Material_Code\n    INNER JOIN Inventory_logs ON Production_logs.Material_Code = Inventory_logs.Material_Code\nGROUP BY Production_logs.Material_Code\nORDER BY Total_Wastage DESC\nLIMIT 1;\n```\n\nThis query will retrieve the material code, total consumption, and total wastage for each material. It will then group the data by material code, calculate the total consumption and wastage for each material, and order the data in descending order based on total wastage. Finally, it will limit the result to only one row, which will give us the material with the highest wastage. ",
    "sql_response": "To find the material with the highest wastage (in Kg) from July 2026 to Dec 2026, we can use the following SQL query:\n\n```sql\nSELECT Material_Code, SUM(Wastage_Kg) AS Total_Wastage_Kg\nFROM inventory_logs\nWHERE Date BETWEEN '2026-07-01' AND '2026-12-31'\nGROUP BY Material_Code\nORDER BY Total_Wastage_Kg DESC;\n```\n\nThis query will calculate the total wastage for each material code and then sort the results in descending order based on the total wastage. The result will show the material code with the highest wastage at the top. ",
    "table_selection_response": "{\n  \"tables\": [\n    \"inventory_logs\"\n  ],\n  \"columns\": [\n    \"Wastage_Kg\"\n  ]\n} ",
    "methodology_score": 88.23529411764706,
    "sql_score": 63.81736526946108,
    "table_column_score": 70.0,
    "response_quality_score": 87.98073625564575,
    "overall_score": 75.10473970517006,
    "methodology_details": {
      "method": "keyword_fallback",
      "overlap_count": 15,
      "expected_keyword_count": 17,
      "response_keyword_count": 105
    },
    "sql_details": {
      "table_match": 100.0,
      "column_match": 20.0,
      "aggregate_match": 50.0,
      "clause_match": 83.33333333333334,
      "fuzzy_score": 75.44910179640718,
      "overall_score": 63.81736526946108,
      "expected_tables": [
        "inventory_logs"
      ],
      "generated_tables": [
        "inventory_logs"
      ],
      "expected_columns": [
        "wastage_kg",
        "sum",
        "material_name"
      ],
      "generated_columns": [
        "wastage_kg",
        "total_wastage_kg",
        "material_code"
      ],
      "has_valid_sql": true
    },
    "table_column_details": {
      "overall_score": 70.0,
      "table_score": 100.0,
      "column_score": 50.0,
      "table_precision": 100.0,
      "table_recall": 100.0,
      "column_precision": 100.0,
      "column_recall": 33.33333333333333,
      "tables_correct": [
        "inventory_logs"
      ],
      "tables_missing": [],
      "tables_extra": [],
      "columns_correct": [
        "wastage_kg"
      ],
      "columns_missing": [
        "material_name",
        "date"
      ],
      "columns_extra": [],
      "expected_tables": [
        "inventory_logs"
      ],
      "generated_tables": [
        "inventory_logs"
      ],
      "expected_columns": [
        "wastage_kg",
        "material_name",
        "date"
      ],
      "generated_columns": [
        "wastage_kg"
      ]
    },
    "total_latency_ms": 12019.263744354248,
    "total_tokens": 2558,
    "errors": [],
    "timestamp": "2025-11-30T13:15:05.339959"
  },
  {
    "question_id": "Complex_31",
    "question_text": "What is the correlation between downtime (in minutes) and failed quantity for each product?",
    "category": "Complex",
    "model_id": "allam-2-7b",
    "methodology_response": "To answer the question about the correlation between downtime (in minutes) and failed quantity for each product, we will follow these steps:\n\n1. Connect to the SQL database and select the required tables:\n```sql\nSELECT * FROM production_logs\nINNER JOIN quality_control ON production_logs.Product = quality_control.Product\nINNER JOIN inventory_logs ON production_logs.Product = inventory_logs.Product\nINNER JOIN maintenance_logs ON production_logs.Product = maintenance_logs.Product;\n```\n2. Filter the data based on the desired product:\n```sql\nSELECT * FROM result WHERE Product = 'Product_Name';\n```\nReplace 'Product_Name' with the actual product name you are interested in.\n3. Calculate the downtime in minutes:\n```sql\nSELECT MIN(DATEDIFF(minute, production_logs.Start_Time, maintenance_logs.Maintenance_Date)) AS Downtime_Minutes FROM result;\n```\n4. Calculate the failed quantity:\n```sql\nSELECT SUM(quality_control.Failed_Qty) AS Failed_Quantity FROM result;\n```\n5. Calculate the correlation between downtime and failed quantity:\n```sql\nSELECT Downtime_Minutes, Failed_Quantity, Downtime_Minutes * Failed_Quantity AS Correlation_Value FROM result;\n```\n6. Filter the data for the desired product:\n```sql\nSELECT Correlation_Value FROM result WHERE Product = 'Product_Name';\n```\nReplace 'Product_Name' with the actual product name you are interested in.\n7. Calculate the average correlation value for the selected product:\n```sql\nSELECT AVG(Correlation_Value) AS Avg_Correlation_Value FROM result WHERE Product = 'Product_Name';\n```\nReplace 'Product_Name' with the actual product name you are interested in.\n\nBy following these steps, we will obtain the correlation between downtime and failed quantity for the desired product and calculate the average correlation value for that product. ",
    "sql_response": "To find the correlation between downtime (in minutes) and failed quantity for each product, we can join the `production_logs` and `quality_control` tables based on the common column `Product`. Then, we can calculate the downtime and failed quantity for each product and join the `inventory_logs` table to get the material details. Finally, we can calculate the average downtime and failed quantity for each product. Here's the SQL query:\n\n```sql\nSELECT \n    production_logs.Product,\n    AVG(production_logs.Downtime_Minutes) AS Avg_Downtime_Minutes,\n    AVG(quality_control.Failed_Qty) AS Avg_Failed_Qty,\n    inventory_logs.Material_Code,\n    inventory_logs.Material_Name,\n    inventory_logs.Unit_Cost_Rupees\nFROM \n    production_logs\nJOIN quality_control ON production_logs.Product = quality_control.Product\nJOIN inventory_logs ON production_logs.Product = inventory_logs.Product\nGROUP BY production_logs.Product, inventory_logs.Material_Code, inventory_logs.Material_Name, inventory_logs.Unit_Cost_Rupees\nORDER BY production_logs.Product;\n```\n\nThis query will give you the average downtime in minutes and failed quantity for each product, along with the material code, material name, and unit cost of the materials used for production. The result will be sorted by the product. ",
    "table_selection_response": "{\n  \"tables\": [\n    \"production_logs\",\n    \"quality_control\"\n  ],\n  \"columns\": [\n    \"Product\",\n    \"Actual_Qty\",\n    \"Failed_Qty\",\n    \"Downtime_Minutes\"\n  ]\n} ",
    "methodology_score": 75.0,
    "sql_score": 46.88691034051859,
    "table_column_score": 91.42857142857143,
    "response_quality_score": 88.73944973945618,
    "overall_score": 70.64150645026997,
    "methodology_details": {
      "method": "keyword_fallback",
      "overlap_count": 12,
      "expected_keyword_count": 16,
      "response_keyword_count": 72
    },
    "sql_details": {
      "table_match": 66.66666666666666,
      "column_match": 27.27272727272727,
      "aggregate_match": 25.0,
      "clause_match": 80.0,
      "fuzzy_score": 42.680412371134025,
      "overall_score": 46.88691034051859,
      "expected_tables": [
        "production_logs",
        "quality_control"
      ],
      "generated_tables": [
        "production_logs",
        "quality_control",
        "inventory_logs"
      ],
      "expected_columns": [
        "pl",
        "product",
        "totalfailedqty",
        "downtime_minutes",
        "totaldowntime",
        "failed_qty",
        "qc"
      ],
      "generated_columns": [
        "material_code",
        "material_name",
        "product",
        "production_logs",
        "downtime_minutes",
        "unit_cost_rupees",
        "failed_qty"
      ],
      "has_valid_sql": true
    },
    "table_column_details": {
      "overall_score": 91.42857142857143,
      "table_score": 100.0,
      "column_score": 85.71428571428571,
      "table_precision": 100.0,
      "table_recall": 100.0,
      "column_precision": 75.0,
      "column_recall": 100.0,
      "tables_correct": [
        "production_logs",
        "quality_control"
      ],
      "tables_missing": [],
      "tables_extra": [],
      "columns_correct": [
        "product",
        "downtime_minutes",
        "failed_qty"
      ],
      "columns_missing": [],
      "columns_extra": [
        "actual_qty"
      ],
      "expected_tables": [
        "production_logs",
        "quality_control"
      ],
      "generated_tables": [
        "production_logs",
        "quality_control"
      ],
      "expected_columns": [
        "product",
        "downtime_minutes",
        "failed_qty"
      ],
      "generated_columns": [
        "product",
        "actual_qty",
        "downtime_minutes",
        "failed_qty"
      ]
    },
    "total_latency_ms": 11260.550260543823,
    "total_tokens": 2392,
    "errors": [],
    "timestamp": "2025-11-30T13:15:23.418392"
  }
]